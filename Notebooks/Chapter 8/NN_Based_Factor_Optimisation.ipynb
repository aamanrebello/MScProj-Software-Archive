{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgLOU8Za1GNq"
      },
      "source": [
        "# Import Repo of Sepsis Simulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGEp1ymaWUpv",
        "outputId": "0f8b0332-319d-4365-9943-d6b1d9172347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gumbel-max-scm'...\n",
            "remote: Enumerating objects: 113, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 113 (delta 0), reused 0 (delta 0), pack-reused 110\u001b[K\n",
            "Receiving objects: 100% (113/113), 1.48 MiB | 3.81 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/clinicalml/gumbel-max-scm.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv2brrpP2WlI"
      },
      "outputs": [],
      "source": [
        "#Enable importing code from parent directory\n",
        "import os, sys\n",
        "simulator_path = os.path.abspath('./gumbel-max-scm')\n",
        "sys.path.insert(1, simulator_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpUoCCBH_Ta8",
        "outputId": "01b8e7a4-26c0-494d-e162-e93ac9cf11d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymdptoolbox\n",
            "  Downloading pymdptoolbox-4.0-b3.zip (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pymdptoolbox) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pymdptoolbox) (1.10.1)\n",
            "Building wheels for collected packages: pymdptoolbox\n",
            "  Building wheel for pymdptoolbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymdptoolbox: filename=pymdptoolbox-4.0b3-py3-none-any.whl size=25657 sha256=1b7fb2ecdb2ff9a110c94e1be268b0dce4dd9b9655b99d17d6832b4b35ff6645\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/e7/c7/d7abf9e309f3573a934fed2750c70bd75d9e9d901f7f16e183\n",
            "Successfully built pymdptoolbox\n",
            "Installing collected packages: pymdptoolbox\n",
            "Successfully installed pymdptoolbox-4.0b3\n"
          ]
        }
      ],
      "source": [
        "!pip install pymdptoolbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VImiXcP9FkB"
      },
      "source": [
        "**IMPORTANT NOTE:** At this stage, to reproduce our experiments, one must modify line 38 of `gumbel-max-scm/sepsisSimDiabetes/DataGenerator.py` so that it reads:\n",
        "\n",
        "```\n",
        "mdp = MDP(init_state_idx=%state%,\n",
        "          policy_array=policy, policy_idx_type=policy_idx_type,\n",
        "          p_diabetes=p_diabetes)\n",
        "\n",
        "```\n",
        "\n",
        "We have essentially set the initial state to a fixed value so that we may estimate the Q-function from that state. Additionally, line 58 of the same file must be modified to:\n",
        "\n",
        "```\n",
        "mdp.state = mdp.get_new_state(state_idx = %state%)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orCP8G0C3DCb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cf.counterfactual as cf\n",
        "import cf.utils as utils\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import itertools as it\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from scipy.linalg import block_diag\n",
        "\n",
        "# Sepsis Simulator code\n",
        "from sepsisSimDiabetes.State import State\n",
        "from sepsisSimDiabetes.Action import Action\n",
        "from sepsisSimDiabetes.DataGenerator import DataGenerator\n",
        "import sepsisSimDiabetes.MDP as simulator\n",
        "\n",
        "import mdptoolboxSrc.mdp as mdptools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zt7QLKc3iQ7"
      },
      "source": [
        "# Set up Variables and Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH6SMENMD-SV"
      },
      "source": [
        "Code taken from [Oberst and Sontag](https://github.com/clinicalml/gumbel-max-scm/blob/master/plots-main-paper.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9gSS-DPD50f"
      },
      "source": [
        "Set up important variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTLB4gBp4Ww-"
      },
      "outputs": [],
      "source": [
        "SEED = 1\n",
        "np.random.seed(SEED)\n",
        "NSIMSAMPS = 100000  # Samples to draw from the simulator\n",
        "NSTEPS = 20  # Max length of each trajectory\n",
        "NCFSAMPS = 5  # Counterfactual Samples per observed sample\n",
        "DISCOUNT_Pol = 0.99 # Used for computing optimal policies\n",
        "DISCOUNT = 1 # Used for computing actual reward\n",
        "PHYS_EPSILON = 0.05 # Used for sampling using physician pol as eps greedy\n",
        "\n",
        "# Option 1: Use bootstrapping w/replacement on the original NSIMSAMPS to estimate errors\n",
        "USE_BOOSTRAP=True\n",
        "N_BOOTSTRAP = 100\n",
        "\n",
        "# Option 2: Use repeated sampling (i.e., NSIMSAMPS fresh simulations each time) to get error bars;\n",
        "# This is done in the appendix of the paper, but not in the main paper\n",
        "N_REPEAT_SAMPLING = 1\n",
        "\n",
        "# These are properties of the simulator, do not change\n",
        "n_actions = Action.NUM_ACTIONS_TOTAL\n",
        "n_components = 2\n",
        "\n",
        "# These are added as absorbing states\n",
        "n_states_abs = State.NUM_OBS_STATES + 2\n",
        "discStateIdx = n_states_abs - 1\n",
        "deadStateIdx = n_states_abs - 2\n",
        "\n",
        "# Number of runs for calculating MSE\n",
        "RUNS = 20\n",
        "# Number of episodes over which we average an OPE estimate\n",
        "N = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUORk1KEedLa"
      },
      "outputs": [],
      "source": [
        "hr_state_mapping = ['Low', 'Normal', 'High']\n",
        "sbp_state_mapping = ['Low', 'Normal', 'High']\n",
        "o2_state_mapping = ['Low', 'Normal']\n",
        "glu_state_mapping = ['Very Low', 'Low', 'Normal', 'High', 'Very High']\n",
        "abx_state_mapping = ['Off', 'On']\n",
        "vaso_state_mapping = ['Off', 'On']\n",
        "vent_state_mapping = ['Off', 'On']\n",
        "diab_state_mapping = ['No', 'Yes']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2A-p4iXLLVn"
      },
      "source": [
        "Set up base for behaviour and evaluation policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmXqCQquBR-b"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"gumbel-max-scm/data/diab_txr_mats-replication.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"gumbel-max-scm/data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHSM6i7nAJwg"
      },
      "outputs": [],
      "source": [
        "# Get the transition and reward matrix from file\n",
        "with open(\"gumbel-max-scm/data/diab_txr_mats-replication.pkl\", \"rb\") as f:\n",
        "    mdict = pickle.load(f)\n",
        "\n",
        "tx_mat = mdict[\"tx_mat\"]\n",
        "r_mat = mdict[\"r_mat\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL5_-lEZBxh6"
      },
      "outputs": [],
      "source": [
        "from scipy.linalg import block_diag\n",
        "\n",
        "tx_mat_full = np.zeros((n_actions, State.NUM_FULL_STATES, State.NUM_FULL_STATES))\n",
        "r_mat_full = np.zeros((n_actions, State.NUM_FULL_STATES, State.NUM_FULL_STATES))\n",
        "\n",
        "# Easily accessible variables\n",
        "A = n_actions\n",
        "S = State.NUM_FULL_STATES\n",
        "\n",
        "for a in range(n_actions):\n",
        "    tx_mat_full[a, ...] = block_diag(tx_mat[0, a, ...], tx_mat[1, a,...])\n",
        "    r_mat_full[a, ...] = block_diag(r_mat[0, a, ...], r_mat[1, a, ...])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc3sZU3pB-xp"
      },
      "outputs": [],
      "source": [
        "fullMDP = cf.MatrixMDP(tx_mat_full, r_mat_full)\n",
        "fullPol = fullMDP.policyIteration(discount=DISCOUNT_Pol, eval_type=1)\n",
        "\n",
        "#The behavior policy is the fully random policy\n",
        "randPol = np.ones(fullPol.shape)/(fullPol.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqM8gH597gjk",
        "outputId": "f02c6fa2-0f63-42af-fc45-60f78d153e0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1440, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#We want the expected reward of starting in a state and taking an action\n",
        "R = np.swapaxes(np.mean(r_mat_full, axis=-1), 0, 1)\n",
        "R.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOSZ8n6_R24G"
      },
      "outputs": [],
      "source": [
        "#To handle -1 states and -1 actions\n",
        "def pad_policy(policy, val=1):\n",
        "  #Add a column of zeroes to the end\n",
        "  policy = np.concatenate((policy, np.full((policy.shape[0], 1), val)), axis=1)\n",
        "  #Add a row of zeroes at the end\n",
        "  policy = np.concatenate((policy, np.full((1, policy.shape[1]), val)), axis=0)\n",
        "  return policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W3Fj_q5EADA"
      },
      "source": [
        "# Load repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY1b2UIxA9Ds",
        "outputId": "2ef17b91-b367-47be-accc-86ba7e504c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Factored-Action-Spaces-for-OPE'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 93 (delta 20), reused 71 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (93/93), 2.94 MiB | 7.52 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ai4ai-lab/Factored-Action-Spaces-for-OPE.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4etBTF2ubmdb"
      },
      "outputs": [],
      "source": [
        "#Enable importing code from parent directory\n",
        "import os, sys\n",
        "main_folder = os.path.abspath('./Factored-Action-Spaces-for-OPE')\n",
        "sys.path.insert(1, main_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SYkHKlIMRj8"
      },
      "source": [
        "# From Patient State 136, With Diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuOvmq-cMxFP"
      },
      "outputs": [],
      "source": [
        "#The patient has diabetes\n",
        "PROB_DIAB = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFB9lbC6M2Ks"
      },
      "source": [
        "### State Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrzAryBORmvz",
        "outputId": "1a8aa474-0cff-4311-ab65-18e3b2ae5ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 2 0 0 0]\n",
            "Heart Rate: Low\n",
            "Systolic Blood Pressure: Normal\n",
            "Percent Oxygen: Normal\n",
            "Glucose Level: Normal\n",
            "Antibiotics: Off\n",
            "Vasopressors: Off\n",
            "Ventilator: Off\n",
            "Diabetes: 1\n"
          ]
        }
      ],
      "source": [
        "#Instantiate a state based on the idx and get the state vector\n",
        "testState = State(state_idx = 136, diabetic_idx=1)\n",
        "vec = testState.get_state_vector()\n",
        "\n",
        "print(vec)\n",
        "\n",
        "print(f'Heart Rate: {hr_state_mapping[vec[0]]}')\n",
        "print(f'Systolic Blood Pressure: {sbp_state_mapping[vec[1]]}')\n",
        "print(f'Percent Oxygen: {o2_state_mapping[vec[2]]}')\n",
        "print(f'Glucose Level: {glu_state_mapping[vec[3]]}')\n",
        "print(f'Antibiotics: {abx_state_mapping[vec[4]]}')\n",
        "print(f'Vasopressors: {vaso_state_mapping[vec[5]]}')\n",
        "print(f'Ventilator: {vent_state_mapping[vec[6]]}')\n",
        "print(f'Diabetes: {testState.diabetic_idx}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPF8wN8gNZEK"
      },
      "source": [
        "### Generate Data From Behaviour Policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGbGvpAiLOr0"
      },
      "source": [
        "Run the data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSAmbkYoDQRe"
      },
      "outputs": [],
      "source": [
        "dgen = DataGenerator()\n",
        "states, actions, lengths, rewards, diab, emp_tx_totals, emp_r_totals = dgen.simulate(\n",
        "    NSIMSAMPS, NSTEPS, policy=randPol, policy_idx_type='full',\n",
        "    p_diabetes=PROB_DIAB, use_tqdm=False) #True, tqdm_desc='Behaviour Policy Simulation')\n",
        "\n",
        "obs_samps = utils.format_dgen_samps(\n",
        "    states, actions, rewards, diab, NSTEPS, NSIMSAMPS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4bhLMTrLQ__"
      },
      "source": [
        "Convert data into array format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsk5poscGNBH",
        "outputId": "0ddccae5-65d6-4a4e-e71d-26d8201bce24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 20, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "time = np.arange(NSTEPS)\n",
        "times = np.stack(axis=0, arrays=[time]*NSIMSAMPS)\n",
        "times = times[..., np.newaxis]\n",
        "\n",
        "nf_tr_b = np.concatenate((times, states[:, 0:NSTEPS, :], actions, rewards, states[:, 1:, :]), axis=2)\n",
        "nf_tr_b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSY3QNm8wgKb",
        "outputId": "534457bf-f28d-43d8-d591-3aba0d893625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[  0. 136.   0.  -1. 168.]\n",
            "  [  1. 168.  -1.   0.  -1.]\n",
            "  [  2.  -1.  -1.   0.  -1.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]\n",
            "\n",
            " [[  0. 136.   3.  -1. 227.]\n",
            "  [  1. 227.  -1.   0.  -1.]\n",
            "  [  2.  -1.  -1.   0.  -1.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]\n",
            "\n",
            " [[  0. 136.   7.   0. 223.]\n",
            "  [  1. 223.   3.   0. 219.]\n",
            "  [  2. 219.   1.   0. 218.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[  0. 136.   2.   0. 377.]\n",
            "  [  1. 377.   4.   0. 372.]\n",
            "  [  2. 372.   7.   0. 463.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]\n",
            "\n",
            " [[  0. 136.   5.   0. 222.]\n",
            "  [  1. 222.   1.   0. 218.]\n",
            "  [  2. 218.   7.  -1. 231.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]\n",
            "\n",
            " [[  0. 136.   7.  -1. 231.]\n",
            "  [  1. 231.  -1.   0.  -1.]\n",
            "  [  2.  -1.  -1.   0.  -1.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]]\n"
          ]
        }
      ],
      "source": [
        "print(nf_tr_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcRSeGkJITQZ"
      },
      "outputs": [],
      "source": [
        "randPol = pad_policy(randPol)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljqSoSVUI_7u"
      },
      "source": [
        "### Varying Episodes $\\epsilon_{e} = 0.4$ (Policy Divergence $4.8^{20}$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WGmgmigI_7v"
      },
      "source": [
        "Set up evaluation policy, generate data and convert into factored format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3Kvf7JwI_7v"
      },
      "outputs": [],
      "source": [
        "EVAL_EPSILON = 0.4\n",
        "\n",
        "evalPolSoft = np.copy(fullPol)\n",
        "evalPolSoft[evalPolSoft == 1] = 1 - EVAL_EPSILON\n",
        "evalPolSoft[evalPolSoft == 0] = EVAL_EPSILON / (n_actions - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT2KzVpCI_7v",
        "outputId": "1d0bb6a3-d1d0-454d-c55e-46f6921bdb0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.8\n"
          ]
        }
      ],
      "source": [
        "# Calculate policy divergence from Voloshin et al.\n",
        "D = 0\n",
        "for state in range(randPol.shape[0] - 1):\n",
        "    for action in range(randPol.shape[1] - 1):\n",
        "        difference = evalPolSoft[state, action]/randPol[state, action]\n",
        "        D = max(D, difference)\n",
        "print(D)\n",
        "shorter_D = round(D,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TreqvybTI_7w"
      },
      "outputs": [],
      "source": [
        "dgen = DataGenerator()\n",
        "states, actions, lengths, rewards, diab, emp_tx_totals, emp_r_totals = dgen.simulate(\n",
        "    NSIMSAMPS, NSTEPS, policy=evalPolSoft, policy_idx_type='full',\n",
        "    p_diabetes=PROB_DIAB, use_tqdm=False) #True, tqdm_desc='Behaviour Policy Simulation')\n",
        "\n",
        "obs_samps = utils.format_dgen_samps(\n",
        "    states, actions, rewards, diab, NSTEPS, NSIMSAMPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69P47oFMI_7w",
        "outputId": "f936f732-f77d-402f-eb86-d00c81ff7f21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 20, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "time = np.arange(NSTEPS)\n",
        "times = np.stack(axis=0, arrays=[time]*NSIMSAMPS)\n",
        "times = times[..., np.newaxis]\n",
        "\n",
        "nf_tr_e = np.concatenate((times, states[:, 0:NSTEPS, :], actions, rewards, states[:, 1:, :]), axis=2)\n",
        "nf_tr_e.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pHiTPTj1VYX",
        "outputId": "a61ac7d6-a119-4404-e386-e59f1db7f866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[  0. 136.   0.   0. 136.]\n",
            "  [  1. 136.   2.   0.  57.]\n",
            "  [  2.  57.   3.  -1. 227.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]\n",
            "\n",
            " [[  0. 136.   2.   0.  57.]\n",
            "  [  1.  57.   4.  -1.  68.]\n",
            "  [  2.  68.  -1.   0.  -1.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]\n",
            "\n",
            " [[  0. 136.   2.   0. 449.]\n",
            "  [  1. 449.   5.   0. 462.]\n",
            "  [  2. 462.   7.   0. 471.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[  0. 136.   2.   0. 145.]\n",
            "  [  1. 145.   3.   0. 147.]\n",
            "  [  2. 147.   2.   0.  57.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]\n",
            "\n",
            " [[  0. 136.   7.   0. 223.]\n",
            "  [  1. 223.   6.   0. 221.]\n",
            "  [  2. 221.   4.   0. 132.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]\n",
            "\n",
            " [[  0. 136.   2.   0.  57.]\n",
            "  [  1.  57.   3.   0. 147.]\n",
            "  [  2. 147.   2.   0. 145.]\n",
            "  ...\n",
            "  [ 17.  -1.  -1.   0.  -1.]\n",
            "  [ 18.  -1.  -1.   0.  -1.]\n",
            "  [ 19.  -1.  -1.   0.  -1.]]]\n"
          ]
        }
      ],
      "source": [
        "print(nf_tr_e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import policy_estimators as pe\n",
        "\n",
        "#Obtain on policy estimate\n",
        "on_policy_estimate = pe.on_policy_Q_estimate(nf_tr_e, DISCOUNT_Pol)"
      ],
      "metadata": {
        "id": "sPMOQPfzh102"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plan\n",
        "\n",
        "- Given data\n",
        "- Objective: lower MSE with respect to on-policy estimate\n",
        "\n",
        "- Evaluate on-policy estimate (true value)\n",
        "- COnstruct a neural network to accept the action and state and output the decomposed policy values and decomposed rewards (2D outputs)\n",
        "- Pass data through network in batches(runs) and based on this find the MSE\n",
        "- Attempt to backpropagate through the network and ultimately obtain the best mapping."
      ],
      "metadata": {
        "id": "D4ZRTG0U_W8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "true_val = torch.as_tensor(on_policy_estimate).to(device)"
      ],
      "metadata": {
        "id": "kbi087bSAVNK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3aa95ef-7f54-4940-ba3f-3b159c41afcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using states and actions"
      ],
      "metadata": {
        "id": "RY2e2oS3wB2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Takes in action and state\n",
        "class FactorNetwork_sa(nn.Module):\n",
        "    def __init__(self, D):\n",
        "        super().__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(2, 15),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(15, 15),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(15, 15),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(15, 3*D),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "f-OIrdKuBdu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop_sa(model, loss_fn, optimizer, discount_factor):\n",
        "    BATCH_SIZE = 1000\n",
        "    train_data = nf_tr_b.reshape((-1, BATCH_SIZE, NSTEPS, 5))\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    #List to hold losses\n",
        "    losses = [0]*10\n",
        "    for run in range(train_data.shape[0]):\n",
        "      loss = torch.zeros((1), dtype=torch.float32).to(device)\n",
        "      batch = train_data[run, :, :, :]\n",
        "      for n in range(BATCH_SIZE):\n",
        "        episode = batch[n, :, :]\n",
        "        #Filter out -1 states and actions\n",
        "        episode = episode[episode[:, 2] != -1, :]\n",
        "        states_and_actions = torch.as_tensor(episode[:, 1:3], dtype=torch.float32).to(device)\n",
        "        # Compute prediction and loss\n",
        "        factored_pol_reward = model(states_and_actions) #Use predictions from network to calculate OPE estimates\n",
        "        D = list(factored_pol_reward.size())[-1]//3\n",
        "        factored_pi_b = factored_pol_reward[:, :D]\n",
        "        factored_pi_e = factored_pol_reward[:, D:2*D]\n",
        "        factored_reward = factored_pol_reward[:, 2*D:]\n",
        "\n",
        "        fn = nn.ReLU()\n",
        "        #Penalty for behaviour policy values < 1\n",
        "        penalty1 = torch.sum(fn(torch.neg(factored_pi_b))).to(device)\n",
        "        #Penalty for behaviour policy values < 1\n",
        "        penalty2 = torch.sum(fn(torch.neg(factored_pi_e))).to(device)\n",
        "        total_penalty = torch.add(penalty1, penalty2).div(episode.shape[0])\n",
        "\n",
        "        pointwise_IS_ratios = torch.div(factored_pi_e, factored_pi_b)\n",
        "        IS_ratios = torch.prod(pointwise_IS_ratios, 0)\n",
        "\n",
        "        times = torch.as_tensor(np.repeat(np.expand_dims(episode[:, 0], axis=1), D, axis=1)).to(device)\n",
        "        # Per-trajectory returns (discounted cumulative rewards)\n",
        "        gamma = torch.full(times.shape, discount_factor).to(device)\n",
        "        G = torch.mul(factored_reward, torch.pow(gamma, times)).sum()\n",
        "\n",
        "        loss.to(device)\n",
        "        loss = torch.add(loss, torch.add(loss_fn(true_val, G), total_penalty).div(BATCH_SIZE))\n",
        "\n",
        "      # Backpropagation\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      if run % 10 == 0:\n",
        "          loss, current = loss.item(), (run + 1) * BATCH_SIZE\n",
        "          print(f\"loss: {loss:>7f}  [{run:>5d} /{train_data.shape[0]:>5d}]\")\n",
        "          losses[run//10] = loss\n",
        "    return losses"
      ],
      "metadata": {
        "id": "nk9h3RO7LptX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = FactorNetwork_sa(2).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 70\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop_sa(model1, loss_fn, optimizer, DISCOUNT_Pol)"
      ],
      "metadata": {
        "id": "yMy56QYA4tjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d014f57a-427f-4d1a-d437-c3870ed9c244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 910.432495  [    0 /  100]\n",
            "loss: 560.977600  [   10 /  100]\n",
            "loss: 703.775940  [   20 /  100]\n",
            "loss: 388.937561  [   30 /  100]\n",
            "loss: 362.888672  [   40 /  100]\n",
            "loss: 316.445068  [   50 /  100]\n",
            "loss: 249.060532  [   60 /  100]\n",
            "loss: 205.999695  [   70 /  100]\n",
            "loss: 108.628403  [   80 /  100]\n",
            "loss: 93.880798  [   90 /  100]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 77.497688  [    0 /  100]\n",
            "loss: 44.504601  [   10 /  100]\n",
            "loss: 48.481956  [   20 /  100]\n",
            "loss: 26.869720  [   30 /  100]\n",
            "loss: 23.171932  [   40 /  100]\n",
            "loss: 19.335766  [   50 /  100]\n",
            "loss: 15.845043  [   60 /  100]\n",
            "loss: 14.151194  [   70 /  100]\n",
            "loss: 11.218729  [   80 /  100]\n",
            "loss: 11.059662  [   90 /  100]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 10.580872  [    0 /  100]\n",
            "loss: 9.576029  [   10 /  100]\n",
            "loss: 9.729786  [   20 /  100]\n",
            "loss: 9.059988  [   30 /  100]\n",
            "loss: 8.978627  [   40 /  100]\n",
            "loss: 8.893556  [   50 /  100]\n",
            "loss: 8.741565  [   60 /  100]\n",
            "loss: 8.630655  [   70 /  100]\n",
            "loss: 8.221783  [   80 /  100]\n",
            "loss: 8.290796  [   90 /  100]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 8.176470  [    0 /  100]\n",
            "loss: 7.893498  [   10 /  100]\n",
            "loss: 7.967834  [   20 /  100]\n",
            "loss: 7.670131  [   30 /  100]\n",
            "loss: 7.602858  [   40 /  100]\n",
            "loss: 7.527419  [   50 /  100]\n",
            "loss: 7.397513  [   60 /  100]\n",
            "loss: 7.296640  [   70 /  100]\n",
            "loss: 6.949640  [   80 /  100]\n",
            "loss: 6.980482  [   90 /  100]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 6.868896  [    0 /  100]\n",
            "loss: 6.617306  [   10 /  100]\n",
            "loss: 6.660546  [   20 /  100]\n",
            "loss: 6.392901  [   30 /  100]\n",
            "loss: 6.322761  [   40 /  100]\n",
            "loss: 6.237620  [   50 /  100]\n",
            "loss: 6.110323  [   60 /  100]\n",
            "loss: 6.012392  [   70 /  100]\n",
            "loss: 5.707851  [   80 /  100]\n",
            "loss: 5.708199  [   90 /  100]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 5.600725  [    0 /  100]\n",
            "loss: 5.372796  [   10 /  100]\n",
            "loss: 5.387461  [   20 /  100]\n",
            "loss: 5.145096  [   30 /  100]\n",
            "loss: 5.070529  [   40 /  100]\n",
            "loss: 4.974880  [   50 /  100]\n",
            "loss: 4.848557  [   60 /  100]\n",
            "loss: 4.752026  [   70 /  100]\n",
            "loss: 4.488369  [   80 /  100]\n",
            "loss: 4.457582  [   90 /  100]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 4.353290  [    0 /  100]\n",
            "loss: 4.148473  [   10 /  100]\n",
            "loss: 4.134206  [   20 /  100]\n",
            "loss: 3.916712  [   30 /  100]\n",
            "loss: 3.837450  [   40 /  100]\n",
            "loss: 3.730647  [   50 /  100]\n",
            "loss: 3.607919  [   60 /  100]\n",
            "loss: 3.521430  [   70 /  100]\n",
            "loss: 3.314028  [   80 /  100]\n",
            "loss: 3.294794  [   90 /  100]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 3.259145  [    0 /  100]\n",
            "loss: 3.141136  [   10 /  100]\n",
            "loss: 3.175083  [   20 /  100]\n",
            "loss: 3.050607  [   30 /  100]\n",
            "loss: 3.042140  [   40 /  100]\n",
            "loss: 3.007396  [   50 /  100]\n",
            "loss: 2.957144  [   60 /  100]\n",
            "loss: 2.942064  [   70 /  100]\n",
            "loss: 2.816148  [   80 /  100]\n",
            "loss: 2.816640  [   90 /  100]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 2.799721  [    0 /  100]\n",
            "loss: 2.699331  [   10 /  100]\n",
            "loss: 2.728630  [   20 /  100]\n",
            "loss: 2.615902  [   30 /  100]\n",
            "loss: 2.607769  [   40 /  100]\n",
            "loss: 2.570928  [   50 /  100]\n",
            "loss: 2.521906  [   60 /  100]\n",
            "loss: 2.507836  [   70 /  100]\n",
            "loss: 2.397476  [   80 /  100]\n",
            "loss: 2.387939  [   90 /  100]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 2.371855  [    0 /  100]\n",
            "loss: 2.280581  [   10 /  100]\n",
            "loss: 2.299930  [   20 /  100]\n",
            "loss: 2.195709  [   30 /  100]\n",
            "loss: 2.185919  [   40 /  100]\n",
            "loss: 2.145595  [   50 /  100]\n",
            "loss: 2.096704  [   60 /  100]\n",
            "loss: 2.082364  [   70 /  100]\n",
            "loss: 1.985399  [   80 /  100]\n",
            "loss: 1.965741  [   90 /  100]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.950044  [    0 /  100]\n",
            "loss: 1.866267  [   10 /  100]\n",
            "loss: 1.875500  [   20 /  100]\n",
            "loss: 1.779156  [   30 /  100]\n",
            "loss: 1.766759  [   40 /  100]\n",
            "loss: 1.722726  [   50 /  100]\n",
            "loss: 1.673507  [   60 /  100]\n",
            "loss: 1.658297  [   70 /  100]\n",
            "loss: 1.574438  [   80 /  100]\n",
            "loss: 1.544355  [   90 /  100]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.528716  [    0 /  100]\n",
            "loss: 1.452228  [   10 /  100]\n",
            "loss: 1.450986  [   20 /  100]\n",
            "loss: 1.362502  [   30 /  100]\n",
            "loss: 1.347219  [   40 /  100]\n",
            "loss: 1.299416  [   50 /  100]\n",
            "loss: 1.249667  [   60 /  100]\n",
            "loss: 1.233387  [   70 /  100]\n",
            "loss: 1.162519  [   80 /  100]\n",
            "loss: 1.121870  [   90 /  100]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.106153  [    0 /  100]\n",
            "loss: 1.036803  [   10 /  100]\n",
            "loss: 1.024899  [   20 /  100]\n",
            "loss: 0.944168  [   30 /  100]\n",
            "loss: 0.925786  [   40 /  100]\n",
            "loss: 0.874327  [   50 /  100]\n",
            "loss: 0.831304  [   60 /  100]\n",
            "loss: 0.829420  [   70 /  100]\n",
            "loss: 0.790199  [   80 /  100]\n",
            "loss: 0.777367  [   90 /  100]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.801081  [    0 /  100]\n",
            "loss: 0.773595  [   10 /  100]\n",
            "loss: 0.802969  [   20 /  100]\n",
            "loss: 0.761499  [   30 /  100]\n",
            "loss: 0.784547  [   40 /  100]\n",
            "loss: 0.774714  [   50 /  100]\n",
            "loss: 0.766964  [   60 /  100]\n",
            "loss: 0.789556  [   70 /  100]\n",
            "loss: 0.766830  [   80 /  100]\n",
            "loss: 0.764106  [   90 /  100]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.789424  [    0 /  100]\n",
            "loss: 0.762137  [   10 /  100]\n",
            "loss: 0.791361  [   20 /  100]\n",
            "loss: 0.750343  [   30 /  100]\n",
            "loss: 0.772430  [   40 /  100]\n",
            "loss: 0.763236  [   50 /  100]\n",
            "loss: 0.755434  [   60 /  100]\n",
            "loss: 0.776917  [   70 /  100]\n",
            "loss: 0.754650  [   80 /  100]\n",
            "loss: 0.752480  [   90 /  100]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.777165  [    0 /  100]\n",
            "loss: 0.750422  [   10 /  100]\n",
            "loss: 0.779153  [   20 /  100]\n",
            "loss: 0.738665  [   30 /  100]\n",
            "loss: 0.759745  [   40 /  100]\n",
            "loss: 0.751230  [   50 /  100]\n",
            "loss: 0.743395  [   60 /  100]\n",
            "loss: 0.763708  [   70 /  100]\n",
            "loss: 0.741963  [   80 /  100]\n",
            "loss: 0.740335  [   90 /  100]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.764335  [    0 /  100]\n",
            "loss: 0.738174  [   10 /  100]\n",
            "loss: 0.766362  [   20 /  100]\n",
            "loss: 0.726435  [   30 /  100]\n",
            "loss: 0.746462  [   40 /  100]\n",
            "loss: 0.738598  [   50 /  100]\n",
            "loss: 0.730800  [   60 /  100]\n",
            "loss: 0.749758  [   70 /  100]\n",
            "loss: 0.728691  [   80 /  100]\n",
            "loss: 0.727550  [   90 /  100]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.750774  [    0 /  100]\n",
            "loss: 0.725276  [   10 /  100]\n",
            "loss: 0.752843  [   20 /  100]\n",
            "loss: 0.713318  [   30 /  100]\n",
            "loss: 0.732114  [   40 /  100]\n",
            "loss: 0.724989  [   50 /  100]\n",
            "loss: 0.716684  [   60 /  100]\n",
            "loss: 0.730352  [   70 /  100]\n",
            "loss: 0.701524  [   80 /  100]\n",
            "loss: 0.674934  [   90 /  100]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.594254  [    0 /  100]\n",
            "loss: 0.395052  [   10 /  100]\n",
            "loss: 0.408096  [   20 /  100]\n",
            "loss: 0.363907  [   30 /  100]\n",
            "loss: 0.358844  [   40 /  100]\n",
            "loss: 0.351745  [   50 /  100]\n",
            "loss: 0.352901  [   60 /  100]\n",
            "loss: 0.324201  [   70 /  100]\n",
            "loss: 0.321900  [   80 /  100]\n",
            "loss: 0.340768  [   90 /  100]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.335565  [    0 /  100]\n",
            "loss: 0.321947  [   10 /  100]\n",
            "loss: 0.341206  [   20 /  100]\n",
            "loss: 0.315958  [   30 /  100]\n",
            "loss: 0.319917  [   40 /  100]\n",
            "loss: 0.312085  [   50 /  100]\n",
            "loss: 0.319441  [   60 /  100]\n",
            "loss: 0.289747  [   70 /  100]\n",
            "loss: 0.295966  [   80 /  100]\n",
            "loss: 0.312891  [   90 /  100]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.307735  [    0 /  100]\n",
            "loss: 0.296468  [   10 /  100]\n",
            "loss: 0.312623  [   20 /  100]\n",
            "loss: 0.293409  [   30 /  100]\n",
            "loss: 0.296535  [   40 /  100]\n",
            "loss: 0.290183  [   50 /  100]\n",
            "loss: 0.299633  [   60 /  100]\n",
            "loss: 0.269601  [   70 /  100]\n",
            "loss: 0.278426  [   80 /  100]\n",
            "loss: 0.295791  [   90 /  100]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.291264  [    0 /  100]\n",
            "loss: 0.280651  [   10 /  100]\n",
            "loss: 0.295033  [   20 /  100]\n",
            "loss: 0.279349  [   30 /  100]\n",
            "loss: 0.282219  [   40 /  100]\n",
            "loss: 0.275081  [   50 /  100]\n",
            "loss: 0.286387  [   60 /  100]\n",
            "loss: 0.256458  [   70 /  100]\n",
            "loss: 0.267231  [   80 /  100]\n",
            "loss: 0.283187  [   90 /  100]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.280940  [    0 /  100]\n",
            "loss: 0.270833  [   10 /  100]\n",
            "loss: 0.282400  [   20 /  100]\n",
            "loss: 0.270069  [   30 /  100]\n",
            "loss: 0.272959  [   40 /  100]\n",
            "loss: 0.264481  [   50 /  100]\n",
            "loss: 0.277569  [   60 /  100]\n",
            "loss: 0.247769  [   70 /  100]\n",
            "loss: 0.260275  [   80 /  100]\n",
            "loss: 0.274165  [   90 /  100]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.274184  [    0 /  100]\n",
            "loss: 0.264058  [   10 /  100]\n",
            "loss: 0.274537  [   20 /  100]\n",
            "loss: 0.264274  [   30 /  100]\n",
            "loss: 0.266676  [   40 /  100]\n",
            "loss: 0.257192  [   50 /  100]\n",
            "loss: 0.271497  [   60 /  100]\n",
            "loss: 0.241991  [   70 /  100]\n",
            "loss: 0.255812  [   80 /  100]\n",
            "loss: 0.267572  [   90 /  100]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.269546  [    0 /  100]\n",
            "loss: 0.258905  [   10 /  100]\n",
            "loss: 0.269550  [   20 /  100]\n",
            "loss: 0.260634  [   30 /  100]\n",
            "loss: 0.262366  [   40 /  100]\n",
            "loss: 0.252071  [   50 /  100]\n",
            "loss: 0.267186  [   60 /  100]\n",
            "loss: 0.237869  [   70 /  100]\n",
            "loss: 0.253079  [   80 /  100]\n",
            "loss: 0.262865  [   90 /  100]\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.266251  [    0 /  100]\n",
            "loss: 0.254789  [   10 /  100]\n",
            "loss: 0.265616  [   20 /  100]\n",
            "loss: 0.257768  [   30 /  100]\n",
            "loss: 0.259203  [   40 /  100]\n",
            "loss: 0.248233  [   50 /  100]\n",
            "loss: 0.264028  [   60 /  100]\n",
            "loss: 0.234763  [   70 /  100]\n",
            "loss: 0.251320  [   80 /  100]\n",
            "loss: 0.259508  [   90 /  100]\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.263785  [    0 /  100]\n",
            "loss: 0.251407  [   10 /  100]\n",
            "loss: 0.262240  [   20 /  100]\n",
            "loss: 0.255251  [   30 /  100]\n",
            "loss: 0.256716  [   40 /  100]\n",
            "loss: 0.244887  [   50 /  100]\n",
            "loss: 0.261563  [   60 /  100]\n",
            "loss: 0.232447  [   70 /  100]\n",
            "loss: 0.250374  [   80 /  100]\n",
            "loss: 0.257379  [   90 /  100]\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.261703  [    0 /  100]\n",
            "loss: 0.248706  [   10 /  100]\n",
            "loss: 0.259179  [   20 /  100]\n",
            "loss: 0.252653  [   30 /  100]\n",
            "loss: 0.254736  [   40 /  100]\n",
            "loss: 0.241993  [   50 /  100]\n",
            "loss: 0.259523  [   60 /  100]\n",
            "loss: 0.230511  [   70 /  100]\n",
            "loss: 0.249163  [   80 /  100]\n",
            "loss: 0.255084  [   90 /  100]\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.259743  [    0 /  100]\n",
            "loss: 0.246470  [   10 /  100]\n",
            "loss: 0.256693  [   20 /  100]\n",
            "loss: 0.250915  [   30 /  100]\n",
            "loss: 0.252894  [   40 /  100]\n",
            "loss: 0.239433  [   50 /  100]\n",
            "loss: 0.257451  [   60 /  100]\n",
            "loss: 0.228747  [   70 /  100]\n",
            "loss: 0.248016  [   80 /  100]\n",
            "loss: 0.252920  [   90 /  100]\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.257776  [    0 /  100]\n",
            "loss: 0.244276  [   10 /  100]\n",
            "loss: 0.254443  [   20 /  100]\n",
            "loss: 0.249076  [   30 /  100]\n",
            "loss: 0.251160  [   40 /  100]\n",
            "loss: 0.237043  [   50 /  100]\n",
            "loss: 0.255443  [   60 /  100]\n",
            "loss: 0.226908  [   70 /  100]\n",
            "loss: 0.247303  [   80 /  100]\n",
            "loss: 0.251447  [   90 /  100]\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.255711  [    0 /  100]\n",
            "loss: 0.241537  [   10 /  100]\n",
            "loss: 0.252017  [   20 /  100]\n",
            "loss: 0.247376  [   30 /  100]\n",
            "loss: 0.249513  [   40 /  100]\n",
            "loss: 0.234758  [   50 /  100]\n",
            "loss: 0.253585  [   60 /  100]\n",
            "loss: 0.224686  [   70 /  100]\n",
            "loss: 0.247106  [   80 /  100]\n",
            "loss: 0.249847  [   90 /  100]\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.252715  [    0 /  100]\n",
            "loss: 0.239033  [   10 /  100]\n",
            "loss: 0.249724  [   20 /  100]\n",
            "loss: 0.246217  [   30 /  100]\n",
            "loss: 0.247070  [   40 /  100]\n",
            "loss: 0.232709  [   50 /  100]\n",
            "loss: 0.251551  [   60 /  100]\n",
            "loss: 0.223401  [   70 /  100]\n",
            "loss: 0.245634  [   80 /  100]\n",
            "loss: 0.248256  [   90 /  100]\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.250271  [    0 /  100]\n",
            "loss: 0.237398  [   10 /  100]\n",
            "loss: 0.247599  [   20 /  100]\n",
            "loss: 0.245021  [   30 /  100]\n",
            "loss: 0.245075  [   40 /  100]\n",
            "loss: 0.230843  [   50 /  100]\n",
            "loss: 0.249663  [   60 /  100]\n",
            "loss: 0.222029  [   70 /  100]\n",
            "loss: 0.244739  [   80 /  100]\n",
            "loss: 0.246561  [   90 /  100]\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.248355  [    0 /  100]\n",
            "loss: 0.235136  [   10 /  100]\n",
            "loss: 0.245700  [   20 /  100]\n",
            "loss: 0.243691  [   30 /  100]\n",
            "loss: 0.243420  [   40 /  100]\n",
            "loss: 0.228892  [   50 /  100]\n",
            "loss: 0.247932  [   60 /  100]\n",
            "loss: 0.220529  [   70 /  100]\n",
            "loss: 0.243900  [   80 /  100]\n",
            "loss: 0.244783  [   90 /  100]\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.246710  [    0 /  100]\n",
            "loss: 0.233231  [   10 /  100]\n",
            "loss: 0.243842  [   20 /  100]\n",
            "loss: 0.242345  [   30 /  100]\n",
            "loss: 0.241816  [   40 /  100]\n",
            "loss: 0.227020  [   50 /  100]\n",
            "loss: 0.246270  [   60 /  100]\n",
            "loss: 0.219125  [   70 /  100]\n",
            "loss: 0.242835  [   80 /  100]\n",
            "loss: 0.242968  [   90 /  100]\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.245098  [    0 /  100]\n",
            "loss: 0.231561  [   10 /  100]\n",
            "loss: 0.242027  [   20 /  100]\n",
            "loss: 0.240965  [   30 /  100]\n",
            "loss: 0.240225  [   40 /  100]\n",
            "loss: 0.225218  [   50 /  100]\n",
            "loss: 0.244673  [   60 /  100]\n",
            "loss: 0.217741  [   70 /  100]\n",
            "loss: 0.241720  [   80 /  100]\n",
            "loss: 0.241170  [   90 /  100]\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.243506  [    0 /  100]\n",
            "loss: 0.230156  [   10 /  100]\n",
            "loss: 0.240214  [   20 /  100]\n",
            "loss: 0.239593  [   30 /  100]\n",
            "loss: 0.238630  [   40 /  100]\n",
            "loss: 0.223450  [   50 /  100]\n",
            "loss: 0.243108  [   60 /  100]\n",
            "loss: 0.216367  [   70 /  100]\n",
            "loss: 0.240573  [   80 /  100]\n",
            "loss: 0.239370  [   90 /  100]\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.241937  [    0 /  100]\n",
            "loss: 0.228832  [   10 /  100]\n",
            "loss: 0.238412  [   20 /  100]\n",
            "loss: 0.238190  [   30 /  100]\n",
            "loss: 0.237004  [   40 /  100]\n",
            "loss: 0.221739  [   50 /  100]\n",
            "loss: 0.241518  [   60 /  100]\n",
            "loss: 0.215066  [   70 /  100]\n",
            "loss: 0.239345  [   80 /  100]\n",
            "loss: 0.237481  [   90 /  100]\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.240382  [    0 /  100]\n",
            "loss: 0.227528  [   10 /  100]\n",
            "loss: 0.236630  [   20 /  100]\n",
            "loss: 0.236784  [   30 /  100]\n",
            "loss: 0.235356  [   40 /  100]\n",
            "loss: 0.220059  [   50 /  100]\n",
            "loss: 0.239901  [   60 /  100]\n",
            "loss: 0.213746  [   70 /  100]\n",
            "loss: 0.238124  [   80 /  100]\n",
            "loss: 0.235560  [   90 /  100]\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.238839  [    0 /  100]\n",
            "loss: 0.226235  [   10 /  100]\n",
            "loss: 0.234894  [   20 /  100]\n",
            "loss: 0.235377  [   30 /  100]\n",
            "loss: 0.233693  [   40 /  100]\n",
            "loss: 0.218426  [   50 /  100]\n",
            "loss: 0.238288  [   60 /  100]\n",
            "loss: 0.212396  [   70 /  100]\n",
            "loss: 0.236922  [   80 /  100]\n",
            "loss: 0.233591  [   90 /  100]\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.237322  [    0 /  100]\n",
            "loss: 0.224953  [   10 /  100]\n",
            "loss: 0.233264  [   20 /  100]\n",
            "loss: 0.233991  [   30 /  100]\n",
            "loss: 0.232016  [   40 /  100]\n",
            "loss: 0.216857  [   50 /  100]\n",
            "loss: 0.236653  [   60 /  100]\n",
            "loss: 0.211051  [   70 /  100]\n",
            "loss: 0.235720  [   80 /  100]\n",
            "loss: 0.231648  [   90 /  100]\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.235815  [    0 /  100]\n",
            "loss: 0.223542  [   10 /  100]\n",
            "loss: 0.231669  [   20 /  100]\n",
            "loss: 0.232585  [   30 /  100]\n",
            "loss: 0.230341  [   40 /  100]\n",
            "loss: 0.215368  [   50 /  100]\n",
            "loss: 0.235028  [   60 /  100]\n",
            "loss: 0.209674  [   70 /  100]\n",
            "loss: 0.234524  [   80 /  100]\n",
            "loss: 0.229736  [   90 /  100]\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.234310  [    0 /  100]\n",
            "loss: 0.221952  [   10 /  100]\n",
            "loss: 0.230041  [   20 /  100]\n",
            "loss: 0.231150  [   30 /  100]\n",
            "loss: 0.228656  [   40 /  100]\n",
            "loss: 0.213949  [   50 /  100]\n",
            "loss: 0.233409  [   60 /  100]\n",
            "loss: 0.208240  [   70 /  100]\n",
            "loss: 0.233346  [   80 /  100]\n",
            "loss: 0.227808  [   90 /  100]\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.232836  [    0 /  100]\n",
            "loss: 0.220336  [   10 /  100]\n",
            "loss: 0.228382  [   20 /  100]\n",
            "loss: 0.229699  [   30 /  100]\n",
            "loss: 0.226978  [   40 /  100]\n",
            "loss: 0.212511  [   50 /  100]\n",
            "loss: 0.231796  [   60 /  100]\n",
            "loss: 0.206848  [   70 /  100]\n",
            "loss: 0.232163  [   80 /  100]\n",
            "loss: 0.226017  [   90 /  100]\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.231369  [    0 /  100]\n",
            "loss: 0.218746  [   10 /  100]\n",
            "loss: 0.226701  [   20 /  100]\n",
            "loss: 0.228201  [   30 /  100]\n",
            "loss: 0.225277  [   40 /  100]\n",
            "loss: 0.211099  [   50 /  100]\n",
            "loss: 0.230197  [   60 /  100]\n",
            "loss: 0.205432  [   70 /  100]\n",
            "loss: 0.230986  [   80 /  100]\n",
            "loss: 0.224260  [   90 /  100]\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.229921  [    0 /  100]\n",
            "loss: 0.217075  [   10 /  100]\n",
            "loss: 0.224988  [   20 /  100]\n",
            "loss: 0.226763  [   30 /  100]\n",
            "loss: 0.223608  [   40 /  100]\n",
            "loss: 0.209684  [   50 /  100]\n",
            "loss: 0.228597  [   60 /  100]\n",
            "loss: 0.204003  [   70 /  100]\n",
            "loss: 0.229807  [   80 /  100]\n",
            "loss: 0.222521  [   90 /  100]\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.228493  [    0 /  100]\n",
            "loss: 0.215501  [   10 /  100]\n",
            "loss: 0.223282  [   20 /  100]\n",
            "loss: 0.225264  [   30 /  100]\n",
            "loss: 0.221908  [   40 /  100]\n",
            "loss: 0.208294  [   50 /  100]\n",
            "loss: 0.227021  [   60 /  100]\n",
            "loss: 0.202566  [   70 /  100]\n",
            "loss: 0.228629  [   80 /  100]\n",
            "loss: 0.220827  [   90 /  100]\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.227049  [    0 /  100]\n",
            "loss: 0.213957  [   10 /  100]\n",
            "loss: 0.221576  [   20 /  100]\n",
            "loss: 0.223768  [   30 /  100]\n",
            "loss: 0.220209  [   40 /  100]\n",
            "loss: 0.206856  [   50 /  100]\n",
            "loss: 0.225446  [   60 /  100]\n",
            "loss: 0.201162  [   70 /  100]\n",
            "loss: 0.227476  [   80 /  100]\n",
            "loss: 0.219110  [   90 /  100]\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.225646  [    0 /  100]\n",
            "loss: 0.212417  [   10 /  100]\n",
            "loss: 0.219938  [   20 /  100]\n",
            "loss: 0.222343  [   30 /  100]\n",
            "loss: 0.218530  [   40 /  100]\n",
            "loss: 0.205449  [   50 /  100]\n",
            "loss: 0.223884  [   60 /  100]\n",
            "loss: 0.199792  [   70 /  100]\n",
            "loss: 0.226329  [   80 /  100]\n",
            "loss: 0.217408  [   90 /  100]\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.224234  [    0 /  100]\n",
            "loss: 0.210902  [   10 /  100]\n",
            "loss: 0.218319  [   20 /  100]\n",
            "loss: 0.220910  [   30 /  100]\n",
            "loss: 0.216881  [   40 /  100]\n",
            "loss: 0.204104  [   50 /  100]\n",
            "loss: 0.222343  [   60 /  100]\n",
            "loss: 0.198473  [   70 /  100]\n",
            "loss: 0.225203  [   80 /  100]\n",
            "loss: 0.215717  [   90 /  100]\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.222857  [    0 /  100]\n",
            "loss: 0.209477  [   10 /  100]\n",
            "loss: 0.216706  [   20 /  100]\n",
            "loss: 0.219479  [   30 /  100]\n",
            "loss: 0.215237  [   40 /  100]\n",
            "loss: 0.202785  [   50 /  100]\n",
            "loss: 0.220792  [   60 /  100]\n",
            "loss: 0.197136  [   70 /  100]\n",
            "loss: 0.224083  [   80 /  100]\n",
            "loss: 0.214042  [   90 /  100]\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.221477  [    0 /  100]\n",
            "loss: 0.207988  [   10 /  100]\n",
            "loss: 0.215068  [   20 /  100]\n",
            "loss: 0.218044  [   30 /  100]\n",
            "loss: 0.213589  [   40 /  100]\n",
            "loss: 0.201525  [   50 /  100]\n",
            "loss: 0.219290  [   60 /  100]\n",
            "loss: 0.195809  [   70 /  100]\n",
            "loss: 0.222966  [   80 /  100]\n",
            "loss: 0.212387  [   90 /  100]\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.220120  [    0 /  100]\n",
            "loss: 0.206538  [   10 /  100]\n",
            "loss: 0.213449  [   20 /  100]\n",
            "loss: 0.216620  [   30 /  100]\n",
            "loss: 0.211982  [   40 /  100]\n",
            "loss: 0.200306  [   50 /  100]\n",
            "loss: 0.217805  [   60 /  100]\n",
            "loss: 0.194519  [   70 /  100]\n",
            "loss: 0.221865  [   80 /  100]\n",
            "loss: 0.210763  [   90 /  100]\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.218797  [    0 /  100]\n",
            "loss: 0.205041  [   10 /  100]\n",
            "loss: 0.211854  [   20 /  100]\n",
            "loss: 0.215223  [   30 /  100]\n",
            "loss: 0.210390  [   40 /  100]\n",
            "loss: 0.199092  [   50 /  100]\n",
            "loss: 0.216315  [   60 /  100]\n",
            "loss: 0.193197  [   70 /  100]\n",
            "loss: 0.220792  [   80 /  100]\n",
            "loss: 0.209163  [   90 /  100]\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.217485  [    0 /  100]\n",
            "loss: 0.203578  [   10 /  100]\n",
            "loss: 0.210275  [   20 /  100]\n",
            "loss: 0.213822  [   30 /  100]\n",
            "loss: 0.208796  [   40 /  100]\n",
            "loss: 0.197896  [   50 /  100]\n",
            "loss: 0.214845  [   60 /  100]\n",
            "loss: 0.191895  [   70 /  100]\n",
            "loss: 0.219728  [   80 /  100]\n",
            "loss: 0.207587  [   90 /  100]\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.216194  [    0 /  100]\n",
            "loss: 0.202134  [   10 /  100]\n",
            "loss: 0.208722  [   20 /  100]\n",
            "loss: 0.212438  [   30 /  100]\n",
            "loss: 0.207202  [   40 /  100]\n",
            "loss: 0.196608  [   50 /  100]\n",
            "loss: 0.213340  [   60 /  100]\n",
            "loss: 0.190715  [   70 /  100]\n",
            "loss: 0.218709  [   80 /  100]\n",
            "loss: 0.206016  [   90 /  100]\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.214922  [    0 /  100]\n",
            "loss: 0.200746  [   10 /  100]\n",
            "loss: 0.207204  [   20 /  100]\n",
            "loss: 0.211077  [   30 /  100]\n",
            "loss: 0.205631  [   40 /  100]\n",
            "loss: 0.195440  [   50 /  100]\n",
            "loss: 0.211883  [   60 /  100]\n",
            "loss: 0.189551  [   70 /  100]\n",
            "loss: 0.217755  [   80 /  100]\n",
            "loss: 0.204416  [   90 /  100]\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.213723  [    0 /  100]\n",
            "loss: 0.199366  [   10 /  100]\n",
            "loss: 0.205705  [   20 /  100]\n",
            "loss: 0.209720  [   30 /  100]\n",
            "loss: 0.204050  [   40 /  100]\n",
            "loss: 0.194240  [   50 /  100]\n",
            "loss: 0.210466  [   60 /  100]\n",
            "loss: 0.188323  [   70 /  100]\n",
            "loss: 0.216722  [   80 /  100]\n",
            "loss: 0.202816  [   90 /  100]\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.212590  [    0 /  100]\n",
            "loss: 0.198102  [   10 /  100]\n",
            "loss: 0.204183  [   20 /  100]\n",
            "loss: 0.208391  [   30 /  100]\n",
            "loss: 0.202484  [   40 /  100]\n",
            "loss: 0.193192  [   50 /  100]\n",
            "loss: 0.209151  [   60 /  100]\n",
            "loss: 0.187011  [   70 /  100]\n",
            "loss: 0.215628  [   80 /  100]\n",
            "loss: 0.201259  [   90 /  100]\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.211492  [    0 /  100]\n",
            "loss: 0.196668  [   10 /  100]\n",
            "loss: 0.202519  [   20 /  100]\n",
            "loss: 0.206972  [   30 /  100]\n",
            "loss: 0.200711  [   40 /  100]\n",
            "loss: 0.191861  [   50 /  100]\n",
            "loss: 0.207591  [   60 /  100]\n",
            "loss: 0.185864  [   70 /  100]\n",
            "loss: 0.214379  [   80 /  100]\n",
            "loss: 0.199746  [   90 /  100]\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.210243  [    0 /  100]\n",
            "loss: 0.195346  [   10 /  100]\n",
            "loss: 0.201098  [   20 /  100]\n",
            "loss: 0.205725  [   30 /  100]\n",
            "loss: 0.199067  [   40 /  100]\n",
            "loss: 0.190486  [   50 /  100]\n",
            "loss: 0.205985  [   60 /  100]\n",
            "loss: 0.184788  [   70 /  100]\n",
            "loss: 0.213233  [   80 /  100]\n",
            "loss: 0.198262  [   90 /  100]\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.209022  [    0 /  100]\n",
            "loss: 0.194094  [   10 /  100]\n",
            "loss: 0.199760  [   20 /  100]\n",
            "loss: 0.204529  [   30 /  100]\n",
            "loss: 0.197531  [   40 /  100]\n",
            "loss: 0.189348  [   50 /  100]\n",
            "loss: 0.204498  [   60 /  100]\n",
            "loss: 0.183726  [   70 /  100]\n",
            "loss: 0.212182  [   80 /  100]\n",
            "loss: 0.196829  [   90 /  100]\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.207854  [    0 /  100]\n",
            "loss: 0.192883  [   10 /  100]\n",
            "loss: 0.198466  [   20 /  100]\n",
            "loss: 0.203395  [   30 /  100]\n",
            "loss: 0.196066  [   40 /  100]\n",
            "loss: 0.188314  [   50 /  100]\n",
            "loss: 0.203132  [   60 /  100]\n",
            "loss: 0.182691  [   70 /  100]\n",
            "loss: 0.211223  [   80 /  100]\n",
            "loss: 0.195430  [   90 /  100]\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.206716  [    0 /  100]\n",
            "loss: 0.191722  [   10 /  100]\n",
            "loss: 0.197227  [   20 /  100]\n",
            "loss: 0.202299  [   30 /  100]\n",
            "loss: 0.194655  [   40 /  100]\n",
            "loss: 0.187360  [   50 /  100]\n",
            "loss: 0.201793  [   60 /  100]\n",
            "loss: 0.181713  [   70 /  100]\n",
            "loss: 0.210337  [   80 /  100]\n",
            "loss: 0.194072  [   90 /  100]\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.205631  [    0 /  100]\n",
            "loss: 0.190601  [   10 /  100]\n",
            "loss: 0.196045  [   20 /  100]\n",
            "loss: 0.201238  [   30 /  100]\n",
            "loss: 0.193283  [   40 /  100]\n",
            "loss: 0.186470  [   50 /  100]\n",
            "loss: 0.200519  [   60 /  100]\n",
            "loss: 0.180747  [   70 /  100]\n",
            "loss: 0.209490  [   80 /  100]\n",
            "loss: 0.192763  [   90 /  100]\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.204599  [    0 /  100]\n",
            "loss: 0.189527  [   10 /  100]\n",
            "loss: 0.194937  [   20 /  100]\n",
            "loss: 0.200216  [   30 /  100]\n",
            "loss: 0.191973  [   40 /  100]\n",
            "loss: 0.185598  [   50 /  100]\n",
            "loss: 0.199273  [   60 /  100]\n",
            "loss: 0.179866  [   70 /  100]\n",
            "loss: 0.208707  [   80 /  100]\n",
            "loss: 0.191497  [   90 /  100]\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.203618  [    0 /  100]\n",
            "loss: 0.188502  [   10 /  100]\n",
            "loss: 0.193834  [   20 /  100]\n",
            "loss: 0.199185  [   30 /  100]\n",
            "loss: 0.190686  [   40 /  100]\n",
            "loss: 0.184844  [   50 /  100]\n",
            "loss: 0.198086  [   60 /  100]\n",
            "loss: 0.179010  [   70 /  100]\n",
            "loss: 0.207940  [   80 /  100]\n",
            "loss: 0.190330  [   90 /  100]\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.202617  [    0 /  100]\n",
            "loss: 0.187524  [   10 /  100]\n",
            "loss: 0.192836  [   20 /  100]\n",
            "loss: 0.198239  [   30 /  100]\n",
            "loss: 0.189462  [   40 /  100]\n",
            "loss: 0.184131  [   50 /  100]\n",
            "loss: 0.196933  [   60 /  100]\n",
            "loss: 0.178149  [   70 /  100]\n",
            "loss: 0.207184  [   80 /  100]\n",
            "loss: 0.189236  [   90 /  100]\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.201540  [    0 /  100]\n",
            "loss: 0.186632  [   10 /  100]\n",
            "loss: 0.191706  [   20 /  100]\n",
            "loss: 0.197240  [   30 /  100]\n",
            "loss: 0.188265  [   40 /  100]\n",
            "loss: 0.183300  [   50 /  100]\n",
            "loss: 0.195718  [   60 /  100]\n",
            "loss: 0.177362  [   70 /  100]\n",
            "loss: 0.206549  [   80 /  100]\n",
            "loss: 0.188171  [   90 /  100]\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.200503  [    0 /  100]\n",
            "loss: 0.185787  [   10 /  100]\n",
            "loss: 0.190569  [   20 /  100]\n",
            "loss: 0.196332  [   30 /  100]\n",
            "loss: 0.187117  [   40 /  100]\n",
            "loss: 0.182516  [   50 /  100]\n",
            "loss: 0.194570  [   60 /  100]\n",
            "loss: 0.176691  [   70 /  100]\n",
            "loss: 0.205891  [   80 /  100]\n",
            "loss: 0.187134  [   90 /  100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = FactorNetwork_sa(3).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 70\n",
        "losses_m2 = [0]*(epochs*10)\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    losses_m2[t*10:(t+1)*10] = train_loop_sa(model2, loss_fn, optimizer, DISCOUNT_Pol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5idY5vb0tY6x",
        "outputId": "596d964b-e0e0-4efa-dc39-4664750e0cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 31.281918  [    0 /  100]\n",
            "loss: 2.077369  [   10 /  100]\n",
            "loss: 0.383725  [   20 /  100]\n",
            "loss: 0.592664  [   30 /  100]\n",
            "loss: 0.356680  [   40 /  100]\n",
            "loss: 0.207474  [   50 /  100]\n",
            "loss: 0.209249  [   60 /  100]\n",
            "loss: 0.210642  [   70 /  100]\n",
            "loss: 0.237120  [   80 /  100]\n",
            "loss: 0.191882  [   90 /  100]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.216831  [    0 /  100]\n",
            "loss: 0.195013  [   10 /  100]\n",
            "loss: 0.197001  [   20 /  100]\n",
            "loss: 0.207180  [   30 /  100]\n",
            "loss: 0.199999  [   40 /  100]\n",
            "loss: 0.195448  [   50 /  100]\n",
            "loss: 0.202571  [   60 /  100]\n",
            "loss: 0.201161  [   70 /  100]\n",
            "loss: 0.234590  [   80 /  100]\n",
            "loss: 0.188575  [   90 /  100]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.212971  [    0 /  100]\n",
            "loss: 0.192249  [   10 /  100]\n",
            "loss: 0.194002  [   20 /  100]\n",
            "loss: 0.204227  [   30 /  100]\n",
            "loss: 0.196321  [   40 /  100]\n",
            "loss: 0.192542  [   50 /  100]\n",
            "loss: 0.199242  [   60 /  100]\n",
            "loss: 0.196735  [   70 /  100]\n",
            "loss: 0.228903  [   80 /  100]\n",
            "loss: 0.185914  [   90 /  100]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.209380  [    0 /  100]\n",
            "loss: 0.189253  [   10 /  100]\n",
            "loss: 0.191037  [   20 /  100]\n",
            "loss: 0.200687  [   30 /  100]\n",
            "loss: 0.192794  [   40 /  100]\n",
            "loss: 0.189430  [   50 /  100]\n",
            "loss: 0.195902  [   60 /  100]\n",
            "loss: 0.192250  [   70 /  100]\n",
            "loss: 0.223260  [   80 /  100]\n",
            "loss: 0.183543  [   90 /  100]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.205475  [    0 /  100]\n",
            "loss: 0.186543  [   10 /  100]\n",
            "loss: 0.188359  [   20 /  100]\n",
            "loss: 0.197452  [   30 /  100]\n",
            "loss: 0.189001  [   40 /  100]\n",
            "loss: 0.186610  [   50 /  100]\n",
            "loss: 0.192829  [   60 /  100]\n",
            "loss: 0.188203  [   70 /  100]\n",
            "loss: 0.217997  [   80 /  100]\n",
            "loss: 0.181482  [   90 /  100]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.201906  [    0 /  100]\n",
            "loss: 0.184176  [   10 /  100]\n",
            "loss: 0.185937  [   20 /  100]\n",
            "loss: 0.194454  [   30 /  100]\n",
            "loss: 0.185490  [   40 /  100]\n",
            "loss: 0.184492  [   50 /  100]\n",
            "loss: 0.190054  [   60 /  100]\n",
            "loss: 0.184801  [   70 /  100]\n",
            "loss: 0.213300  [   80 /  100]\n",
            "loss: 0.179698  [   90 /  100]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.199377  [    0 /  100]\n",
            "loss: 0.182334  [   10 /  100]\n",
            "loss: 0.184356  [   20 /  100]\n",
            "loss: 0.192305  [   30 /  100]\n",
            "loss: 0.182407  [   40 /  100]\n",
            "loss: 0.183238  [   50 /  100]\n",
            "loss: 0.188212  [   60 /  100]\n",
            "loss: 0.182162  [   70 /  100]\n",
            "loss: 0.209944  [   80 /  100]\n",
            "loss: 0.178239  [   90 /  100]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.197618  [    0 /  100]\n",
            "loss: 0.181161  [   10 /  100]\n",
            "loss: 0.183377  [   20 /  100]\n",
            "loss: 0.190904  [   30 /  100]\n",
            "loss: 0.179984  [   40 /  100]\n",
            "loss: 0.182139  [   50 /  100]\n",
            "loss: 0.187014  [   60 /  100]\n",
            "loss: 0.180187  [   70 /  100]\n",
            "loss: 0.207522  [   80 /  100]\n",
            "loss: 0.177401  [   90 /  100]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.196213  [    0 /  100]\n",
            "loss: 0.180461  [   10 /  100]\n",
            "loss: 0.182909  [   20 /  100]\n",
            "loss: 0.189934  [   30 /  100]\n",
            "loss: 0.178488  [   40 /  100]\n",
            "loss: 0.181399  [   50 /  100]\n",
            "loss: 0.186121  [   60 /  100]\n",
            "loss: 0.178813  [   70 /  100]\n",
            "loss: 0.205710  [   80 /  100]\n",
            "loss: 0.176940  [   90 /  100]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.195227  [    0 /  100]\n",
            "loss: 0.180036  [   10 /  100]\n",
            "loss: 0.182764  [   20 /  100]\n",
            "loss: 0.189285  [   30 /  100]\n",
            "loss: 0.177522  [   40 /  100]\n",
            "loss: 0.180978  [   50 /  100]\n",
            "loss: 0.185495  [   60 /  100]\n",
            "loss: 0.177794  [   70 /  100]\n",
            "loss: 0.204313  [   80 /  100]\n",
            "loss: 0.176668  [   90 /  100]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.194467  [    0 /  100]\n",
            "loss: 0.179749  [   10 /  100]\n",
            "loss: 0.182658  [   20 /  100]\n",
            "loss: 0.188845  [   30 /  100]\n",
            "loss: 0.176828  [   40 /  100]\n",
            "loss: 0.180744  [   50 /  100]\n",
            "loss: 0.185104  [   60 /  100]\n",
            "loss: 0.177067  [   70 /  100]\n",
            "loss: 0.203283  [   80 /  100]\n",
            "loss: 0.176605  [   90 /  100]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.193925  [    0 /  100]\n",
            "loss: 0.179555  [   10 /  100]\n",
            "loss: 0.182448  [   20 /  100]\n",
            "loss: 0.188531  [   30 /  100]\n",
            "loss: 0.176332  [   40 /  100]\n",
            "loss: 0.180628  [   50 /  100]\n",
            "loss: 0.184915  [   60 /  100]\n",
            "loss: 0.176607  [   70 /  100]\n",
            "loss: 0.202572  [   80 /  100]\n",
            "loss: 0.176665  [   90 /  100]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.193568  [    0 /  100]\n",
            "loss: 0.179430  [   10 /  100]\n",
            "loss: 0.182391  [   20 /  100]\n",
            "loss: 0.188307  [   30 /  100]\n",
            "loss: 0.176011  [   40 /  100]\n",
            "loss: 0.180519  [   50 /  100]\n",
            "loss: 0.184819  [   60 /  100]\n",
            "loss: 0.176291  [   70 /  100]\n",
            "loss: 0.202009  [   80 /  100]\n",
            "loss: 0.176667  [   90 /  100]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.193314  [    0 /  100]\n",
            "loss: 0.179413  [   10 /  100]\n",
            "loss: 0.182654  [   20 /  100]\n",
            "loss: 0.188176  [   30 /  100]\n",
            "loss: 0.175775  [   40 /  100]\n",
            "loss: 0.180528  [   50 /  100]\n",
            "loss: 0.184797  [   60 /  100]\n",
            "loss: 0.176086  [   70 /  100]\n",
            "loss: 0.201556  [   80 /  100]\n",
            "loss: 0.176609  [   90 /  100]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.193184  [    0 /  100]\n",
            "loss: 0.179464  [   10 /  100]\n",
            "loss: 0.182838  [   20 /  100]\n",
            "loss: 0.188101  [   30 /  100]\n",
            "loss: 0.175601  [   40 /  100]\n",
            "loss: 0.180539  [   50 /  100]\n",
            "loss: 0.184811  [   60 /  100]\n",
            "loss: 0.175921  [   70 /  100]\n",
            "loss: 0.201228  [   80 /  100]\n",
            "loss: 0.176550  [   90 /  100]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.193122  [    0 /  100]\n",
            "loss: 0.179500  [   10 /  100]\n",
            "loss: 0.182757  [   20 /  100]\n",
            "loss: 0.188066  [   30 /  100]\n",
            "loss: 0.175532  [   40 /  100]\n",
            "loss: 0.180519  [   50 /  100]\n",
            "loss: 0.184913  [   60 /  100]\n",
            "loss: 0.175814  [   70 /  100]\n",
            "loss: 0.201051  [   80 /  100]\n",
            "loss: 0.176536  [   90 /  100]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.193046  [    0 /  100]\n",
            "loss: 0.179508  [   10 /  100]\n",
            "loss: 0.182613  [   20 /  100]\n",
            "loss: 0.188028  [   30 /  100]\n",
            "loss: 0.175578  [   40 /  100]\n",
            "loss: 0.180533  [   50 /  100]\n",
            "loss: 0.185233  [   60 /  100]\n",
            "loss: 0.175663  [   70 /  100]\n",
            "loss: 0.201028  [   80 /  100]\n",
            "loss: 0.176572  [   90 /  100]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.192962  [    0 /  100]\n",
            "loss: 0.179529  [   10 /  100]\n",
            "loss: 0.182536  [   20 /  100]\n",
            "loss: 0.187993  [   30 /  100]\n",
            "loss: 0.175678  [   40 /  100]\n",
            "loss: 0.180580  [   50 /  100]\n",
            "loss: 0.185678  [   60 /  100]\n",
            "loss: 0.175451  [   70 /  100]\n",
            "loss: 0.201064  [   80 /  100]\n",
            "loss: 0.176729  [   90 /  100]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.192958  [    0 /  100]\n",
            "loss: 0.179572  [   10 /  100]\n",
            "loss: 0.182388  [   20 /  100]\n",
            "loss: 0.187985  [   30 /  100]\n",
            "loss: 0.175744  [   40 /  100]\n",
            "loss: 0.180668  [   50 /  100]\n",
            "loss: 0.185996  [   60 /  100]\n",
            "loss: 0.175444  [   70 /  100]\n",
            "loss: 0.200964  [   80 /  100]\n",
            "loss: 0.176920  [   90 /  100]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.193110  [    0 /  100]\n",
            "loss: 0.179545  [   10 /  100]\n",
            "loss: 0.182256  [   20 /  100]\n",
            "loss: 0.188097  [   30 /  100]\n",
            "loss: 0.175587  [   40 /  100]\n",
            "loss: 0.180748  [   50 /  100]\n",
            "loss: 0.186056  [   60 /  100]\n",
            "loss: 0.175691  [   70 /  100]\n",
            "loss: 0.200792  [   80 /  100]\n",
            "loss: 0.176842  [   90 /  100]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.193191  [    0 /  100]\n",
            "loss: 0.179505  [   10 /  100]\n",
            "loss: 0.182330  [   20 /  100]\n",
            "loss: 0.188224  [   30 /  100]\n",
            "loss: 0.175407  [   40 /  100]\n",
            "loss: 0.180734  [   50 /  100]\n",
            "loss: 0.186380  [   60 /  100]\n",
            "loss: 0.176180  [   70 /  100]\n",
            "loss: 0.200686  [   80 /  100]\n",
            "loss: 0.176590  [   90 /  100]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.192956  [    0 /  100]\n",
            "loss: 0.179510  [   10 /  100]\n",
            "loss: 0.182480  [   20 /  100]\n",
            "loss: 0.188259  [   30 /  100]\n",
            "loss: 0.175358  [   40 /  100]\n",
            "loss: 0.180716  [   50 /  100]\n",
            "loss: 0.187023  [   60 /  100]\n",
            "loss: 0.177098  [   70 /  100]\n",
            "loss: 0.200712  [   80 /  100]\n",
            "loss: 0.176444  [   90 /  100]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.192720  [    0 /  100]\n",
            "loss: 0.179524  [   10 /  100]\n",
            "loss: 0.182336  [   20 /  100]\n",
            "loss: 0.188523  [   30 /  100]\n",
            "loss: 0.175208  [   40 /  100]\n",
            "loss: 0.180670  [   50 /  100]\n",
            "loss: 0.188096  [   60 /  100]\n",
            "loss: 0.178448  [   70 /  100]\n",
            "loss: 0.200836  [   80 /  100]\n",
            "loss: 0.176530  [   90 /  100]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.192867  [    0 /  100]\n",
            "loss: 0.179715  [   10 /  100]\n",
            "loss: 0.182103  [   20 /  100]\n",
            "loss: 0.188953  [   30 /  100]\n",
            "loss: 0.175106  [   40 /  100]\n",
            "loss: 0.180667  [   50 /  100]\n",
            "loss: 0.189378  [   60 /  100]\n",
            "loss: 0.179742  [   70 /  100]\n",
            "loss: 0.200834  [   80 /  100]\n",
            "loss: 0.176493  [   90 /  100]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.192897  [    0 /  100]\n",
            "loss: 0.179829  [   10 /  100]\n",
            "loss: 0.182148  [   20 /  100]\n",
            "loss: 0.188788  [   30 /  100]\n",
            "loss: 0.175315  [   40 /  100]\n",
            "loss: 0.180698  [   50 /  100]\n",
            "loss: 0.190025  [   60 /  100]\n",
            "loss: 0.179813  [   70 /  100]\n",
            "loss: 0.200694  [   80 /  100]\n",
            "loss: 0.176372  [   90 /  100]\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.192715  [    0 /  100]\n",
            "loss: 0.179719  [   10 /  100]\n",
            "loss: 0.182530  [   20 /  100]\n",
            "loss: 0.188480  [   30 /  100]\n",
            "loss: 0.175727  [   40 /  100]\n",
            "loss: 0.180713  [   50 /  100]\n",
            "loss: 0.191331  [   60 /  100]\n",
            "loss: 0.179415  [   70 /  100]\n",
            "loss: 0.200829  [   80 /  100]\n",
            "loss: 0.176475  [   90 /  100]\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.192667  [    0 /  100]\n",
            "loss: 0.179677  [   10 /  100]\n",
            "loss: 0.183027  [   20 /  100]\n",
            "loss: 0.188412  [   30 /  100]\n",
            "loss: 0.175982  [   40 /  100]\n",
            "loss: 0.180744  [   50 /  100]\n",
            "loss: 0.193189  [   60 /  100]\n",
            "loss: 0.178164  [   70 /  100]\n",
            "loss: 0.201406  [   80 /  100]\n",
            "loss: 0.176446  [   90 /  100]\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.192934  [    0 /  100]\n",
            "loss: 0.179680  [   10 /  100]\n",
            "loss: 0.184170  [   20 /  100]\n",
            "loss: 0.188454  [   30 /  100]\n",
            "loss: 0.175999  [   40 /  100]\n",
            "loss: 0.180919  [   50 /  100]\n",
            "loss: 0.194556  [   60 /  100]\n",
            "loss: 0.176375  [   70 /  100]\n",
            "loss: 0.201912  [   80 /  100]\n",
            "loss: 0.176352  [   90 /  100]\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.193592  [    0 /  100]\n",
            "loss: 0.179523  [   10 /  100]\n",
            "loss: 0.187373  [   20 /  100]\n",
            "loss: 0.189145  [   30 /  100]\n",
            "loss: 0.175646  [   40 /  100]\n",
            "loss: 0.181091  [   50 /  100]\n",
            "loss: 0.193962  [   60 /  100]\n",
            "loss: 0.175477  [   70 /  100]\n",
            "loss: 0.201560  [   80 /  100]\n",
            "loss: 0.177505  [   90 /  100]\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.193406  [    0 /  100]\n",
            "loss: 0.179675  [   10 /  100]\n",
            "loss: 0.190204  [   20 /  100]\n",
            "loss: 0.191198  [   30 /  100]\n",
            "loss: 0.175899  [   40 /  100]\n",
            "loss: 0.181142  [   50 /  100]\n",
            "loss: 0.193419  [   60 /  100]\n",
            "loss: 0.175835  [   70 /  100]\n",
            "loss: 0.200967  [   80 /  100]\n",
            "loss: 0.178948  [   90 /  100]\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.192667  [    0 /  100]\n",
            "loss: 0.180102  [   10 /  100]\n",
            "loss: 0.189217  [   20 /  100]\n",
            "loss: 0.192540  [   30 /  100]\n",
            "loss: 0.177226  [   40 /  100]\n",
            "loss: 0.181715  [   50 /  100]\n",
            "loss: 0.193823  [   60 /  100]\n",
            "loss: 0.177158  [   70 /  100]\n",
            "loss: 0.200752  [   80 /  100]\n",
            "loss: 0.179423  [   90 /  100]\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.192478  [    0 /  100]\n",
            "loss: 0.180136  [   10 /  100]\n",
            "loss: 0.187017  [   20 /  100]\n",
            "loss: 0.192031  [   30 /  100]\n",
            "loss: 0.178536  [   40 /  100]\n",
            "loss: 0.183130  [   50 /  100]\n",
            "loss: 0.192625  [   60 /  100]\n",
            "loss: 0.179111  [   70 /  100]\n",
            "loss: 0.201245  [   80 /  100]\n",
            "loss: 0.178359  [   90 /  100]\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.192687  [    0 /  100]\n",
            "loss: 0.179829  [   10 /  100]\n",
            "loss: 0.185753  [   20 /  100]\n",
            "loss: 0.191051  [   30 /  100]\n",
            "loss: 0.178911  [   40 /  100]\n",
            "loss: 0.184703  [   50 /  100]\n",
            "loss: 0.189927  [   60 /  100]\n",
            "loss: 0.180226  [   70 /  100]\n",
            "loss: 0.202154  [   80 /  100]\n",
            "loss: 0.176786  [   90 /  100]\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.192595  [    0 /  100]\n",
            "loss: 0.179638  [   10 /  100]\n",
            "loss: 0.185692  [   20 /  100]\n",
            "loss: 0.190689  [   30 /  100]\n",
            "loss: 0.178922  [   40 /  100]\n",
            "loss: 0.185926  [   50 /  100]\n",
            "loss: 0.187324  [   60 /  100]\n",
            "loss: 0.179942  [   70 /  100]\n",
            "loss: 0.202696  [   80 /  100]\n",
            "loss: 0.176169  [   90 /  100]\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.192387  [    0 /  100]\n",
            "loss: 0.179677  [   10 /  100]\n",
            "loss: 0.185818  [   20 /  100]\n",
            "loss: 0.190500  [   30 /  100]\n",
            "loss: 0.178732  [   40 /  100]\n",
            "loss: 0.186772  [   50 /  100]\n",
            "loss: 0.185365  [   60 /  100]\n",
            "loss: 0.178680  [   70 /  100]\n",
            "loss: 0.202567  [   80 /  100]\n",
            "loss: 0.176414  [   90 /  100]\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.192546  [    0 /  100]\n",
            "loss: 0.179980  [   10 /  100]\n",
            "loss: 0.185184  [   20 /  100]\n",
            "loss: 0.189709  [   30 /  100]\n",
            "loss: 0.177688  [   40 /  100]\n",
            "loss: 0.186604  [   50 /  100]\n",
            "loss: 0.184167  [   60 /  100]\n",
            "loss: 0.177050  [   70 /  100]\n",
            "loss: 0.201980  [   80 /  100]\n",
            "loss: 0.176710  [   90 /  100]\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.192848  [    0 /  100]\n",
            "loss: 0.180547  [   10 /  100]\n",
            "loss: 0.183903  [   20 /  100]\n",
            "loss: 0.188470  [   30 /  100]\n",
            "loss: 0.175825  [   40 /  100]\n",
            "loss: 0.184814  [   50 /  100]\n",
            "loss: 0.183732  [   60 /  100]\n",
            "loss: 0.175944  [   70 /  100]\n",
            "loss: 0.201490  [   80 /  100]\n",
            "loss: 0.176799  [   90 /  100]\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.192969  [    0 /  100]\n",
            "loss: 0.181095  [   10 /  100]\n",
            "loss: 0.182763  [   20 /  100]\n",
            "loss: 0.187762  [   30 /  100]\n",
            "loss: 0.174602  [   40 /  100]\n",
            "loss: 0.182386  [   50 /  100]\n",
            "loss: 0.183671  [   60 /  100]\n",
            "loss: 0.175638  [   70 /  100]\n",
            "loss: 0.201452  [   80 /  100]\n",
            "loss: 0.177234  [   90 /  100]\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.193233  [    0 /  100]\n",
            "loss: 0.181650  [   10 /  100]\n",
            "loss: 0.182104  [   20 /  100]\n",
            "loss: 0.188014  [   30 /  100]\n",
            "loss: 0.175123  [   40 /  100]\n",
            "loss: 0.181132  [   50 /  100]\n",
            "loss: 0.183707  [   60 /  100]\n",
            "loss: 0.175620  [   70 /  100]\n",
            "loss: 0.201639  [   80 /  100]\n",
            "loss: 0.178210  [   90 /  100]\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.193636  [    0 /  100]\n",
            "loss: 0.182201  [   10 /  100]\n",
            "loss: 0.181873  [   20 /  100]\n",
            "loss: 0.188615  [   30 /  100]\n",
            "loss: 0.176358  [   40 /  100]\n",
            "loss: 0.180990  [   50 /  100]\n",
            "loss: 0.183741  [   60 /  100]\n",
            "loss: 0.175614  [   70 /  100]\n",
            "loss: 0.201577  [   80 /  100]\n",
            "loss: 0.178807  [   90 /  100]\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.193407  [    0 /  100]\n",
            "loss: 0.182040  [   10 /  100]\n",
            "loss: 0.181930  [   20 /  100]\n",
            "loss: 0.188639  [   30 /  100]\n",
            "loss: 0.176935  [   40 /  100]\n",
            "loss: 0.181011  [   50 /  100]\n",
            "loss: 0.183637  [   60 /  100]\n",
            "loss: 0.175687  [   70 /  100]\n",
            "loss: 0.201499  [   80 /  100]\n",
            "loss: 0.179390  [   90 /  100]\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.192944  [    0 /  100]\n",
            "loss: 0.181384  [   10 /  100]\n",
            "loss: 0.182388  [   20 /  100]\n",
            "loss: 0.188372  [   30 /  100]\n",
            "loss: 0.177380  [   40 /  100]\n",
            "loss: 0.181020  [   50 /  100]\n",
            "loss: 0.183572  [   60 /  100]\n",
            "loss: 0.175892  [   70 /  100]\n",
            "loss: 0.201688  [   80 /  100]\n",
            "loss: 0.180724  [   90 /  100]\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.192588  [    0 /  100]\n",
            "loss: 0.180693  [   10 /  100]\n",
            "loss: 0.183477  [   20 /  100]\n",
            "loss: 0.188217  [   30 /  100]\n",
            "loss: 0.178227  [   40 /  100]\n",
            "loss: 0.181048  [   50 /  100]\n",
            "loss: 0.183637  [   60 /  100]\n",
            "loss: 0.176092  [   70 /  100]\n",
            "loss: 0.202061  [   80 /  100]\n",
            "loss: 0.182270  [   90 /  100]\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.192314  [    0 /  100]\n",
            "loss: 0.180159  [   10 /  100]\n",
            "loss: 0.184751  [   20 /  100]\n",
            "loss: 0.188251  [   30 /  100]\n",
            "loss: 0.179232  [   40 /  100]\n",
            "loss: 0.181100  [   50 /  100]\n",
            "loss: 0.183788  [   60 /  100]\n",
            "loss: 0.176216  [   70 /  100]\n",
            "loss: 0.202437  [   80 /  100]\n",
            "loss: 0.183360  [   90 /  100]\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.192205  [    0 /  100]\n",
            "loss: 0.179872  [   10 /  100]\n",
            "loss: 0.185526  [   20 /  100]\n",
            "loss: 0.188393  [   30 /  100]\n",
            "loss: 0.179904  [   40 /  100]\n",
            "loss: 0.181184  [   50 /  100]\n",
            "loss: 0.183951  [   60 /  100]\n",
            "loss: 0.176250  [   70 /  100]\n",
            "loss: 0.202758  [   80 /  100]\n",
            "loss: 0.184019  [   90 /  100]\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.192212  [    0 /  100]\n",
            "loss: 0.179736  [   10 /  100]\n",
            "loss: 0.185840  [   20 /  100]\n",
            "loss: 0.188540  [   30 /  100]\n",
            "loss: 0.180195  [   40 /  100]\n",
            "loss: 0.181286  [   50 /  100]\n",
            "loss: 0.184069  [   60 /  100]\n",
            "loss: 0.176224  [   70 /  100]\n",
            "loss: 0.203001  [   80 /  100]\n",
            "loss: 0.184331  [   90 /  100]\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.192271  [    0 /  100]\n",
            "loss: 0.179667  [   10 /  100]\n",
            "loss: 0.185889  [   20 /  100]\n",
            "loss: 0.188683  [   30 /  100]\n",
            "loss: 0.180262  [   40 /  100]\n",
            "loss: 0.181394  [   50 /  100]\n",
            "loss: 0.184151  [   60 /  100]\n",
            "loss: 0.176175  [   70 /  100]\n",
            "loss: 0.203194  [   80 /  100]\n",
            "loss: 0.184476  [   90 /  100]\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.192361  [    0 /  100]\n",
            "loss: 0.179627  [   10 /  100]\n",
            "loss: 0.185789  [   20 /  100]\n",
            "loss: 0.188820  [   30 /  100]\n",
            "loss: 0.180237  [   40 /  100]\n",
            "loss: 0.181511  [   50 /  100]\n",
            "loss: 0.184214  [   60 /  100]\n",
            "loss: 0.176120  [   70 /  100]\n",
            "loss: 0.203366  [   80 /  100]\n",
            "loss: 0.184524  [   90 /  100]\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.192476  [    0 /  100]\n",
            "loss: 0.179602  [   10 /  100]\n",
            "loss: 0.185631  [   20 /  100]\n",
            "loss: 0.188956  [   30 /  100]\n",
            "loss: 0.180145  [   40 /  100]\n",
            "loss: 0.181633  [   50 /  100]\n",
            "loss: 0.184263  [   60 /  100]\n",
            "loss: 0.176054  [   70 /  100]\n",
            "loss: 0.203502  [   80 /  100]\n",
            "loss: 0.184426  [   90 /  100]\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.192620  [    0 /  100]\n",
            "loss: 0.179585  [   10 /  100]\n",
            "loss: 0.185366  [   20 /  100]\n",
            "loss: 0.189103  [   30 /  100]\n",
            "loss: 0.179917  [   40 /  100]\n",
            "loss: 0.181782  [   50 /  100]\n",
            "loss: 0.184291  [   60 /  100]\n",
            "loss: 0.175974  [   70 /  100]\n",
            "loss: 0.203639  [   80 /  100]\n",
            "loss: 0.184260  [   90 /  100]\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.192832  [    0 /  100]\n",
            "loss: 0.179573  [   10 /  100]\n",
            "loss: 0.184982  [   20 /  100]\n",
            "loss: 0.189261  [   30 /  100]\n",
            "loss: 0.179586  [   40 /  100]\n",
            "loss: 0.181976  [   50 /  100]\n",
            "loss: 0.184310  [   60 /  100]\n",
            "loss: 0.175884  [   70 /  100]\n",
            "loss: 0.203766  [   80 /  100]\n",
            "loss: 0.183890  [   90 /  100]\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.193141  [    0 /  100]\n",
            "loss: 0.179566  [   10 /  100]\n",
            "loss: 0.184432  [   20 /  100]\n",
            "loss: 0.189465  [   30 /  100]\n",
            "loss: 0.179046  [   40 /  100]\n",
            "loss: 0.182234  [   50 /  100]\n",
            "loss: 0.184284  [   60 /  100]\n",
            "loss: 0.175797  [   70 /  100]\n",
            "loss: 0.203860  [   80 /  100]\n",
            "loss: 0.183238  [   90 /  100]\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.193624  [    0 /  100]\n",
            "loss: 0.179563  [   10 /  100]\n",
            "loss: 0.183644  [   20 /  100]\n",
            "loss: 0.189679  [   30 /  100]\n",
            "loss: 0.178210  [   40 /  100]\n",
            "loss: 0.182585  [   50 /  100]\n",
            "loss: 0.184180  [   60 /  100]\n",
            "loss: 0.175767  [   70 /  100]\n",
            "loss: 0.203836  [   80 /  100]\n",
            "loss: 0.182040  [   90 /  100]\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.194396  [    0 /  100]\n",
            "loss: 0.179579  [   10 /  100]\n",
            "loss: 0.182581  [   20 /  100]\n",
            "loss: 0.189817  [   30 /  100]\n",
            "loss: 0.176895  [   40 /  100]\n",
            "loss: 0.183009  [   50 /  100]\n",
            "loss: 0.183910  [   60 /  100]\n",
            "loss: 0.175973  [   70 /  100]\n",
            "loss: 0.203498  [   80 /  100]\n",
            "loss: 0.180122  [   90 /  100]\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.195442  [    0 /  100]\n",
            "loss: 0.179682  [   10 /  100]\n",
            "loss: 0.181766  [   20 /  100]\n",
            "loss: 0.189564  [   30 /  100]\n",
            "loss: 0.175433  [   40 /  100]\n",
            "loss: 0.183252  [   50 /  100]\n",
            "loss: 0.183538  [   60 /  100]\n",
            "loss: 0.176604  [   70 /  100]\n",
            "loss: 0.202659  [   80 /  100]\n",
            "loss: 0.178004  [   90 /  100]\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.196152  [    0 /  100]\n",
            "loss: 0.180093  [   10 /  100]\n",
            "loss: 0.182133  [   20 /  100]\n",
            "loss: 0.188750  [   30 /  100]\n",
            "loss: 0.174616  [   40 /  100]\n",
            "loss: 0.183065  [   50 /  100]\n",
            "loss: 0.183373  [   60 /  100]\n",
            "loss: 0.177332  [   70 /  100]\n",
            "loss: 0.201785  [   80 /  100]\n",
            "loss: 0.176791  [   90 /  100]\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.196147  [    0 /  100]\n",
            "loss: 0.180831  [   10 /  100]\n",
            "loss: 0.182862  [   20 /  100]\n",
            "loss: 0.188040  [   30 /  100]\n",
            "loss: 0.174536  [   40 /  100]\n",
            "loss: 0.183022  [   50 /  100]\n",
            "loss: 0.183419  [   60 /  100]\n",
            "loss: 0.177907  [   70 /  100]\n",
            "loss: 0.201237  [   80 /  100]\n",
            "loss: 0.176330  [   90 /  100]\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.195822  [    0 /  100]\n",
            "loss: 0.181525  [   10 /  100]\n",
            "loss: 0.182894  [   20 /  100]\n",
            "loss: 0.187763  [   30 /  100]\n",
            "loss: 0.174782  [   40 /  100]\n",
            "loss: 0.183450  [   50 /  100]\n",
            "loss: 0.183568  [   60 /  100]\n",
            "loss: 0.178460  [   70 /  100]\n",
            "loss: 0.201033  [   80 /  100]\n",
            "loss: 0.176239  [   90 /  100]\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.195695  [    0 /  100]\n",
            "loss: 0.182010  [   10 /  100]\n",
            "loss: 0.182613  [   20 /  100]\n",
            "loss: 0.187684  [   30 /  100]\n",
            "loss: 0.175186  [   40 /  100]\n",
            "loss: 0.184146  [   50 /  100]\n",
            "loss: 0.183943  [   60 /  100]\n",
            "loss: 0.178704  [   70 /  100]\n",
            "loss: 0.201066  [   80 /  100]\n",
            "loss: 0.176409  [   90 /  100]\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.196163  [    0 /  100]\n",
            "loss: 0.182510  [   10 /  100]\n",
            "loss: 0.182459  [   20 /  100]\n",
            "loss: 0.187658  [   30 /  100]\n",
            "loss: 0.175622  [   40 /  100]\n",
            "loss: 0.184875  [   50 /  100]\n",
            "loss: 0.184571  [   60 /  100]\n",
            "loss: 0.178604  [   70 /  100]\n",
            "loss: 0.201136  [   80 /  100]\n",
            "loss: 0.176736  [   90 /  100]\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.197047  [    0 /  100]\n",
            "loss: 0.183262  [   10 /  100]\n",
            "loss: 0.182392  [   20 /  100]\n",
            "loss: 0.187655  [   30 /  100]\n",
            "loss: 0.176047  [   40 /  100]\n",
            "loss: 0.185500  [   50 /  100]\n",
            "loss: 0.185306  [   60 /  100]\n",
            "loss: 0.178310  [   70 /  100]\n",
            "loss: 0.201149  [   80 /  100]\n",
            "loss: 0.177066  [   90 /  100]\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.197923  [    0 /  100]\n",
            "loss: 0.184095  [   10 /  100]\n",
            "loss: 0.182273  [   20 /  100]\n",
            "loss: 0.187657  [   30 /  100]\n",
            "loss: 0.176329  [   40 /  100]\n",
            "loss: 0.185909  [   50 /  100]\n",
            "loss: 0.185999  [   60 /  100]\n",
            "loss: 0.177996  [   70 /  100]\n",
            "loss: 0.201140  [   80 /  100]\n",
            "loss: 0.177306  [   90 /  100]\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.198561  [    0 /  100]\n",
            "loss: 0.184819  [   10 /  100]\n",
            "loss: 0.182117  [   20 /  100]\n",
            "loss: 0.187651  [   30 /  100]\n",
            "loss: 0.176454  [   40 /  100]\n",
            "loss: 0.186106  [   50 /  100]\n",
            "loss: 0.186553  [   60 /  100]\n",
            "loss: 0.177742  [   70 /  100]\n",
            "loss: 0.201130  [   80 /  100]\n",
            "loss: 0.177462  [   90 /  100]\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.198976  [    0 /  100]\n",
            "loss: 0.185377  [   10 /  100]\n",
            "loss: 0.181989  [   20 /  100]\n",
            "loss: 0.187648  [   30 /  100]\n",
            "loss: 0.176461  [   40 /  100]\n",
            "loss: 0.186158  [   50 /  100]\n",
            "loss: 0.186964  [   60 /  100]\n",
            "loss: 0.177551  [   70 /  100]\n",
            "loss: 0.201120  [   80 /  100]\n",
            "loss: 0.177558  [   90 /  100]\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.199236  [    0 /  100]\n",
            "loss: 0.185786  [   10 /  100]\n",
            "loss: 0.181891  [   20 /  100]\n",
            "loss: 0.187644  [   30 /  100]\n",
            "loss: 0.176440  [   40 /  100]\n",
            "loss: 0.186153  [   50 /  100]\n",
            "loss: 0.187249  [   60 /  100]\n",
            "loss: 0.177420  [   70 /  100]\n",
            "loss: 0.201119  [   80 /  100]\n",
            "loss: 0.177628  [   90 /  100]\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.199409  [    0 /  100]\n",
            "loss: 0.186062  [   10 /  100]\n",
            "loss: 0.181828  [   20 /  100]\n",
            "loss: 0.187643  [   30 /  100]\n",
            "loss: 0.176418  [   40 /  100]\n",
            "loss: 0.186150  [   50 /  100]\n",
            "loss: 0.187463  [   60 /  100]\n",
            "loss: 0.177343  [   70 /  100]\n",
            "loss: 0.201120  [   80 /  100]\n",
            "loss: 0.177668  [   90 /  100]\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.199520  [    0 /  100]\n",
            "loss: 0.186274  [   10 /  100]\n",
            "loss: 0.181784  [   20 /  100]\n",
            "loss: 0.187641  [   30 /  100]\n",
            "loss: 0.176382  [   40 /  100]\n",
            "loss: 0.186121  [   50 /  100]\n",
            "loss: 0.187603  [   60 /  100]\n",
            "loss: 0.177271  [   70 /  100]\n",
            "loss: 0.201114  [   80 /  100]\n",
            "loss: 0.177693  [   90 /  100]\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.199578  [    0 /  100]\n",
            "loss: 0.186415  [   10 /  100]\n",
            "loss: 0.181754  [   20 /  100]\n",
            "loss: 0.187640  [   30 /  100]\n",
            "loss: 0.176346  [   40 /  100]\n",
            "loss: 0.186097  [   50 /  100]\n",
            "loss: 0.187716  [   60 /  100]\n",
            "loss: 0.177238  [   70 /  100]\n",
            "loss: 0.201126  [   80 /  100]\n",
            "loss: 0.177720  [   90 /  100]\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.199641  [    0 /  100]\n",
            "loss: 0.186516  [   10 /  100]\n",
            "loss: 0.181734  [   20 /  100]\n",
            "loss: 0.187638  [   30 /  100]\n",
            "loss: 0.176323  [   40 /  100]\n",
            "loss: 0.186083  [   50 /  100]\n",
            "loss: 0.187777  [   60 /  100]\n",
            "loss: 0.177210  [   70 /  100]\n",
            "loss: 0.201126  [   80 /  100]\n",
            "loss: 0.177732  [   90 /  100]\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.199677  [    0 /  100]\n",
            "loss: 0.186586  [   10 /  100]\n",
            "loss: 0.181720  [   20 /  100]\n",
            "loss: 0.187638  [   30 /  100]\n",
            "loss: 0.176303  [   40 /  100]\n",
            "loss: 0.186073  [   50 /  100]\n",
            "loss: 0.187837  [   60 /  100]\n",
            "loss: 0.177181  [   70 /  100]\n",
            "loss: 0.201128  [   80 /  100]\n",
            "loss: 0.177743  [   90 /  100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using policy and reward"
      ],
      "metadata": {
        "id": "cRc_LErrwFiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Takes in policy values and reward at state and action\n",
        "class FactorNetwork_pr(nn.Module):\n",
        "    def __init__(self, D):\n",
        "        super().__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(3, 10),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(10, 10),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(10, 10),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(10, 3*D),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "aUzgHz6NucE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop_pr(model, loss_fn, optimizer, discount_factor, pi_b, pi_e):\n",
        "    BATCH_SIZE = 1000\n",
        "    train_data = nf_tr_b.reshape((-1, BATCH_SIZE, NSTEPS, 5))\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    #List to hold losses\n",
        "    losses = [0]*10\n",
        "    for run in range(train_data.shape[0]):\n",
        "      loss = torch.zeros((1), dtype=torch.float32).to(device)\n",
        "      batch = train_data[run, :, :, :]\n",
        "      for n in range(BATCH_SIZE):\n",
        "        episode = batch[n, :, :]\n",
        "        #Filter out -1 states and actions\n",
        "        episode = episode[episode[:, 2] != -1, :]\n",
        "        S = episode[:, 1].astype('int32')\n",
        "        A = episode[:,2].astype('int32')\n",
        "        states_and_actions = torch.as_tensor(np.stack((pi_b[S, A], pi_e[S, A], episode[:,3]), axis=-1), dtype=torch.float32).to(device)\n",
        "        # Compute prediction and loss\n",
        "        factored_pol_reward = model(states_and_actions) #Use predictions from network to calculate OPE estimates\n",
        "        D = list(factored_pol_reward.size())[-1]//3\n",
        "        factored_pi_b = factored_pol_reward[:, :D]\n",
        "        factored_pi_e = factored_pol_reward[:, D:2*D]\n",
        "        factored_reward = factored_pol_reward[:, 2*D:]\n",
        "\n",
        "        fn = nn.ReLU()\n",
        "        #Penalty for behaviour policy values < 1\n",
        "        penalty1 = torch.sum(fn(torch.neg(factored_pi_b))).to(device)\n",
        "        #Penalty for behaviour policy values < 1\n",
        "        penalty2 = torch.sum(fn(torch.neg(factored_pi_e))).to(device)\n",
        "        total_penalty = torch.add(penalty1, penalty2).div(episode.shape[0])\n",
        "\n",
        "        pointwise_IS_ratios = torch.div(factored_pi_e, factored_pi_b)\n",
        "        IS_ratios = torch.prod(pointwise_IS_ratios, 0)\n",
        "\n",
        "        times = torch.as_tensor(np.repeat(np.expand_dims(episode[:, 0], axis=1), D, axis=1)).to(device)\n",
        "        # Per-trajectory returns (discounted cumulative rewards)\n",
        "        gamma = torch.full(times.shape, discount_factor).to(device)\n",
        "        G = torch.mul(factored_reward, torch.pow(gamma, times)).sum()\n",
        "\n",
        "        loss.to(device)\n",
        "        loss = torch.add(loss, torch.add(loss_fn(true_val, G), total_penalty).div(BATCH_SIZE))\n",
        "\n",
        "      # Backpropagation\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      if run % 10 == 0:\n",
        "          loss, current = loss.item(), (run + 1) * BATCH_SIZE\n",
        "          print(f\"loss: {loss:>7f}  [{run:>5d} /{train_data.shape[0]:>5d}]\")\n",
        "          losses[run//10] = loss\n",
        "    return losses"
      ],
      "metadata": {
        "id": "4CbGJoIIwHiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = FactorNetwork_pr(2).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model3.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 70\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop_pr(model3, loss_fn, optimizer, DISCOUNT_Pol, randPol, evalPolSoft)"
      ],
      "metadata": {
        "id": "R-RDcBzOwptz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8ecbe3-c66a-47e9-d701-e0b6336d40b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.008138  [    0 /  100]\n",
            "loss: 0.007609  [   10 /  100]\n",
            "loss: 0.010534  [   20 /  100]\n",
            "loss: 0.008381  [   30 /  100]\n",
            "loss: 0.008179  [   40 /  100]\n",
            "loss: 0.011056  [   50 /  100]\n",
            "loss: 0.009743  [   60 /  100]\n",
            "loss: 0.007587  [   70 /  100]\n",
            "loss: 0.012430  [   80 /  100]\n",
            "loss: 0.011529  [   90 /  100]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.007857  [    0 /  100]\n",
            "loss: 0.007291  [   10 /  100]\n",
            "loss: 0.010218  [   20 /  100]\n",
            "loss: 0.008046  [   30 /  100]\n",
            "loss: 0.007954  [   40 /  100]\n",
            "loss: 0.010700  [   50 /  100]\n",
            "loss: 0.009365  [   60 /  100]\n",
            "loss: 0.007323  [   70 /  100]\n",
            "loss: 0.011955  [   80 /  100]\n",
            "loss: 0.011143  [   90 /  100]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.007626  [    0 /  100]\n",
            "loss: 0.007037  [   10 /  100]\n",
            "loss: 0.009940  [   20 /  100]\n",
            "loss: 0.007792  [   30 /  100]\n",
            "loss: 0.007750  [   40 /  100]\n",
            "loss: 0.010409  [   50 /  100]\n",
            "loss: 0.009052  [   60 /  100]\n",
            "loss: 0.007098  [   70 /  100]\n",
            "loss: 0.011559  [   80 /  100]\n",
            "loss: 0.010807  [   90 /  100]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.007422  [    0 /  100]\n",
            "loss: 0.006824  [   10 /  100]\n",
            "loss: 0.009709  [   20 /  100]\n",
            "loss: 0.007572  [   30 /  100]\n",
            "loss: 0.007583  [   40 /  100]\n",
            "loss: 0.010146  [   50 /  100]\n",
            "loss: 0.008773  [   60 /  100]\n",
            "loss: 0.006903  [   70 /  100]\n",
            "loss: 0.011180  [   80 /  100]\n",
            "loss: 0.010499  [   90 /  100]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.007255  [    0 /  100]\n",
            "loss: 0.006643  [   10 /  100]\n",
            "loss: 0.009495  [   20 /  100]\n",
            "loss: 0.007380  [   30 /  100]\n",
            "loss: 0.007430  [   40 /  100]\n",
            "loss: 0.009901  [   50 /  100]\n",
            "loss: 0.008527  [   60 /  100]\n",
            "loss: 0.006735  [   70 /  100]\n",
            "loss: 0.010844  [   80 /  100]\n",
            "loss: 0.010213  [   90 /  100]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.007136  [    0 /  100]\n",
            "loss: 0.006492  [   10 /  100]\n",
            "loss: 0.009277  [   20 /  100]\n",
            "loss: 0.007222  [   30 /  100]\n",
            "loss: 0.007271  [   40 /  100]\n",
            "loss: 0.009673  [   50 /  100]\n",
            "loss: 0.008303  [   60 /  100]\n",
            "loss: 0.006582  [   70 /  100]\n",
            "loss: 0.010524  [   80 /  100]\n",
            "loss: 0.009946  [   90 /  100]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.006978  [    0 /  100]\n",
            "loss: 0.006334  [   10 /  100]\n",
            "loss: 0.009113  [   20 /  100]\n",
            "loss: 0.007053  [   30 /  100]\n",
            "loss: 0.007147  [   40 /  100]\n",
            "loss: 0.009449  [   50 /  100]\n",
            "loss: 0.008087  [   60 /  100]\n",
            "loss: 0.006445  [   70 /  100]\n",
            "loss: 0.010212  [   80 /  100]\n",
            "loss: 0.009686  [   90 /  100]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.006851  [    0 /  100]\n",
            "loss: 0.006196  [   10 /  100]\n",
            "loss: 0.008923  [   20 /  100]\n",
            "loss: 0.006900  [   30 /  100]\n",
            "loss: 0.006994  [   40 /  100]\n",
            "loss: 0.009226  [   50 /  100]\n",
            "loss: 0.007879  [   60 /  100]\n",
            "loss: 0.006301  [   70 /  100]\n",
            "loss: 0.009920  [   80 /  100]\n",
            "loss: 0.009427  [   90 /  100]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.006713  [    0 /  100]\n",
            "loss: 0.006061  [   10 /  100]\n",
            "loss: 0.008749  [   20 /  100]\n",
            "loss: 0.006750  [   30 /  100]\n",
            "loss: 0.006866  [   40 /  100]\n",
            "loss: 0.009005  [   50 /  100]\n",
            "loss: 0.007672  [   60 /  100]\n",
            "loss: 0.006168  [   70 /  100]\n",
            "loss: 0.009618  [   80 /  100]\n",
            "loss: 0.009171  [   90 /  100]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.006583  [    0 /  100]\n",
            "loss: 0.005927  [   10 /  100]\n",
            "loss: 0.008567  [   20 /  100]\n",
            "loss: 0.006602  [   30 /  100]\n",
            "loss: 0.006723  [   40 /  100]\n",
            "loss: 0.008782  [   50 /  100]\n",
            "loss: 0.007467  [   60 /  100]\n",
            "loss: 0.006031  [   70 /  100]\n",
            "loss: 0.009325  [   80 /  100]\n",
            "loss: 0.008916  [   90 /  100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = FactorNetwork_pr(3).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model4.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 40\n",
        "losses_m4 = [0]*epochs*10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    losses_m4[t*10:(t+1)*10] = train_loop_pr(model4, loss_fn, optimizer, DISCOUNT_Pol, randPol, evalPolSoft)"
      ],
      "metadata": {
        "id": "cs0YQfA4wpuW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066feeea-5392-4792-a0a0-3eec09fc675e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 6.580877  [    0 /  100]\n",
            "loss: 5.748127  [   10 /  100]\n",
            "loss: 6.489702  [   20 /  100]\n",
            "loss: 5.572906  [   30 /  100]\n",
            "loss: 5.607388  [   40 /  100]\n",
            "loss: 5.423065  [   50 /  100]\n",
            "loss: 5.160678  [   60 /  100]\n",
            "loss: 5.434678  [   70 /  100]\n",
            "loss: 4.825305  [   80 /  100]\n",
            "loss: 4.763486  [   90 /  100]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 4.846787  [    0 /  100]\n",
            "loss: 4.263735  [   10 /  100]\n",
            "loss: 4.725530  [   20 /  100]\n",
            "loss: 4.094279  [   30 /  100]\n",
            "loss: 4.091607  [   40 /  100]\n",
            "loss: 3.936630  [   50 /  100]\n",
            "loss: 3.736750  [   60 /  100]\n",
            "loss: 3.888947  [   70 /  100]\n",
            "loss: 3.472434  [   80 /  100]\n",
            "loss: 3.404456  [   90 /  100]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 3.425740  [    0 /  100]\n",
            "loss: 3.044214  [   10 /  100]\n",
            "loss: 3.296467  [   20 /  100]\n",
            "loss: 2.889802  [   30 /  100]\n",
            "loss: 2.862955  [   40 /  100]\n",
            "loss: 2.736969  [   50 /  100]\n",
            "loss: 2.586803  [   60 /  100]\n",
            "loss: 2.627303  [   70 /  100]\n",
            "loss: 2.334267  [   80 /  100]\n",
            "loss: 2.234569  [   90 /  100]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.177216  [    0 /  100]\n",
            "loss: 1.931318  [   10 /  100]\n",
            "loss: 1.981925  [   20 /  100]\n",
            "loss: 1.741945  [   30 /  100]\n",
            "loss: 1.678303  [   40 /  100]\n",
            "loss: 1.579783  [   50 /  100]\n",
            "loss: 1.480952  [   60 /  100]\n",
            "loss: 1.463517  [   70 /  100]\n",
            "loss: 1.324842  [   80 /  100]\n",
            "loss: 1.255958  [   90 /  100]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.201515  [    0 /  100]\n",
            "loss: 1.097339  [   10 /  100]\n",
            "loss: 1.082025  [   20 /  100]\n",
            "loss: 0.989548  [   30 /  100]\n",
            "loss: 0.944218  [   40 /  100]\n",
            "loss: 0.887021  [   50 /  100]\n",
            "loss: 0.834130  [   60 /  100]\n",
            "loss: 0.799129  [   70 /  100]\n",
            "loss: 0.745664  [   80 /  100]\n",
            "loss: 0.705184  [   90 /  100]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.666832  [    0 /  100]\n",
            "loss: 0.631320  [   10 /  100]\n",
            "loss: 0.599887  [   20 /  100]\n",
            "loss: 0.572149  [   30 /  100]\n",
            "loss: 0.542293  [   40 /  100]\n",
            "loss: 0.518764  [   50 /  100]\n",
            "loss: 0.497125  [   60 /  100]\n",
            "loss: 0.465354  [   70 /  100]\n",
            "loss: 0.454021  [   80 /  100]\n",
            "loss: 0.437089  [   90 /  100]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.419379  [    0 /  100]\n",
            "loss: 0.408581  [   10 /  100]\n",
            "loss: 0.390678  [   20 /  100]\n",
            "loss: 0.380757  [   30 /  100]\n",
            "loss: 0.362181  [   40 /  100]\n",
            "loss: 0.357869  [   50 /  100]\n",
            "loss: 0.350143  [   60 /  100]\n",
            "loss: 0.326383  [   70 /  100]\n",
            "loss: 0.327339  [   80 /  100]\n",
            "loss: 0.325502  [   90 /  100]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.324206  [    0 /  100]\n",
            "loss: 0.312987  [   10 /  100]\n",
            "loss: 0.316256  [   20 /  100]\n",
            "loss: 0.301022  [   30 /  100]\n",
            "loss: 0.287843  [   40 /  100]\n",
            "loss: 0.292381  [   50 /  100]\n",
            "loss: 0.288996  [   60 /  100]\n",
            "loss: 0.273060  [   70 /  100]\n",
            "loss: 0.272668  [   80 /  100]\n",
            "loss: 0.279498  [   90 /  100]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.289441  [    0 /  100]\n",
            "loss: 0.270577  [   10 /  100]\n",
            "loss: 0.292613  [   20 /  100]\n",
            "loss: 0.267740  [   30 /  100]\n",
            "loss: 0.259132  [   40 /  100]\n",
            "loss: 0.268005  [   50 /  100]\n",
            "loss: 0.266381  [   60 /  100]\n",
            "loss: 0.255377  [   70 /  100]\n",
            "loss: 0.253364  [   80 /  100]\n",
            "loss: 0.262756  [   90 /  100]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.275350  [    0 /  100]\n",
            "loss: 0.254894  [   10 /  100]\n",
            "loss: 0.280264  [   20 /  100]\n",
            "loss: 0.253497  [   30 /  100]\n",
            "loss: 0.245685  [   40 /  100]\n",
            "loss: 0.254495  [   50 /  100]\n",
            "loss: 0.252779  [   60 /  100]\n",
            "loss: 0.242807  [   70 /  100]\n",
            "loss: 0.240272  [   80 /  100]\n",
            "loss: 0.249367  [   90 /  100]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.261538  [    0 /  100]\n",
            "loss: 0.241306  [   10 /  100]\n",
            "loss: 0.266006  [   20 /  100]\n",
            "loss: 0.239578  [   30 /  100]\n",
            "loss: 0.232159  [   40 /  100]\n",
            "loss: 0.240495  [   50 /  100]\n",
            "loss: 0.238691  [   60 /  100]\n",
            "loss: 0.229370  [   70 /  100]\n",
            "loss: 0.226661  [   80 /  100]\n",
            "loss: 0.235103  [   90 /  100]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.246618  [    0 /  100]\n",
            "loss: 0.226700  [   10 /  100]\n",
            "loss: 0.250830  [   20 /  100]\n",
            "loss: 0.224556  [   30 /  100]\n",
            "loss: 0.217563  [   40 /  100]\n",
            "loss: 0.225616  [   50 /  100]\n",
            "loss: 0.223826  [   60 /  100]\n",
            "loss: 0.215589  [   70 /  100]\n",
            "loss: 0.212396  [   80 /  100]\n",
            "loss: 0.220498  [   90 /  100]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.231460  [    0 /  100]\n",
            "loss: 0.211808  [   10 /  100]\n",
            "loss: 0.235343  [   20 /  100]\n",
            "loss: 0.209545  [   30 /  100]\n",
            "loss: 0.202757  [   40 /  100]\n",
            "loss: 0.210360  [   50 /  100]\n",
            "loss: 0.208689  [   60 /  100]\n",
            "loss: 0.201044  [   70 /  100]\n",
            "loss: 0.197772  [   80 /  100]\n",
            "loss: 0.204999  [   90 /  100]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.214661  [    0 /  100]\n",
            "loss: 0.195901  [   10 /  100]\n",
            "loss: 0.217840  [   20 /  100]\n",
            "loss: 0.193421  [   30 /  100]\n",
            "loss: 0.186820  [   40 /  100]\n",
            "loss: 0.193941  [   50 /  100]\n",
            "loss: 0.192557  [   60 /  100]\n",
            "loss: 0.185458  [   70 /  100]\n",
            "loss: 0.182565  [   80 /  100]\n",
            "loss: 0.188797  [   90 /  100]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.196965  [    0 /  100]\n",
            "loss: 0.179750  [   10 /  100]\n",
            "loss: 0.199278  [   20 /  100]\n",
            "loss: 0.176743  [   30 /  100]\n",
            "loss: 0.170208  [   40 /  100]\n",
            "loss: 0.176647  [   50 /  100]\n",
            "loss: 0.175440  [   60 /  100]\n",
            "loss: 0.168758  [   70 /  100]\n",
            "loss: 0.166180  [   80 /  100]\n",
            "loss: 0.171252  [   90 /  100]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.177759  [    0 /  100]\n",
            "loss: 0.161977  [   10 /  100]\n",
            "loss: 0.179191  [   20 /  100]\n",
            "loss: 0.158470  [   30 /  100]\n",
            "loss: 0.152032  [   40 /  100]\n",
            "loss: 0.157819  [   50 /  100]\n",
            "loss: 0.156798  [   60 /  100]\n",
            "loss: 0.150672  [   70 /  100]\n",
            "loss: 0.148339  [   80 /  100]\n",
            "loss: 0.152273  [   90 /  100]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.157062  [    0 /  100]\n",
            "loss: 0.142785  [   10 /  100]\n",
            "loss: 0.157699  [   20 /  100]\n",
            "loss: 0.138885  [   30 /  100]\n",
            "loss: 0.132745  [   40 /  100]\n",
            "loss: 0.137944  [   50 /  100]\n",
            "loss: 0.137214  [   60 /  100]\n",
            "loss: 0.131783  [   70 /  100]\n",
            "loss: 0.129929  [   80 /  100]\n",
            "loss: 0.132819  [   90 /  100]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.136054  [    0 /  100]\n",
            "loss: 0.123519  [   10 /  100]\n",
            "loss: 0.136197  [   20 /  100]\n",
            "loss: 0.119582  [   30 /  100]\n",
            "loss: 0.113757  [   40 /  100]\n",
            "loss: 0.118409  [   50 /  100]\n",
            "loss: 0.117954  [   60 /  100]\n",
            "loss: 0.113150  [   70 /  100]\n",
            "loss: 0.111805  [   80 /  100]\n",
            "loss: 0.113674  [   90 /  100]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.115331  [    0 /  100]\n",
            "loss: 0.104507  [   10 /  100]\n",
            "loss: 0.114941  [   20 /  100]\n",
            "loss: 0.100525  [   30 /  100]\n",
            "loss: 0.095097  [   40 /  100]\n",
            "loss: 0.099222  [   50 /  100]\n",
            "loss: 0.099017  [   60 /  100]\n",
            "loss: 0.094837  [   70 /  100]\n",
            "loss: 0.094097  [   80 /  100]\n",
            "loss: 0.095018  [   90 /  100]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.095157  [    0 /  100]\n",
            "loss: 0.086142  [   10 /  100]\n",
            "loss: 0.094422  [   20 /  100]\n",
            "loss: 0.082230  [   30 /  100]\n",
            "loss: 0.077267  [   40 /  100]\n",
            "loss: 0.080971  [   50 /  100]\n",
            "loss: 0.080992  [   60 /  100]\n",
            "loss: 0.077393  [   70 /  100]\n",
            "loss: 0.077304  [   80 /  100]\n",
            "loss: 0.077409  [   90 /  100]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.076247  [    0 /  100]\n",
            "loss: 0.068993  [   10 /  100]\n",
            "loss: 0.075415  [   20 /  100]\n",
            "loss: 0.065358  [   30 /  100]\n",
            "loss: 0.060945  [   40 /  100]\n",
            "loss: 0.064248  [   50 /  100]\n",
            "loss: 0.064505  [   60 /  100]\n",
            "loss: 0.061461  [   70 /  100]\n",
            "loss: 0.062069  [   80 /  100]\n",
            "loss: 0.061538  [   90 /  100]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.059310  [    0 /  100]\n",
            "loss: 0.053706  [   10 /  100]\n",
            "loss: 0.058468  [   20 /  100]\n",
            "loss: 0.050474  [   30 /  100]\n",
            "loss: 0.046635  [   40 /  100]\n",
            "loss: 0.049658  [   50 /  100]\n",
            "loss: 0.050079  [   60 /  100]\n",
            "loss: 0.047510  [   70 /  100]\n",
            "loss: 0.048799  [   80 /  100]\n",
            "loss: 0.047815  [   90 /  100]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.044779  [    0 /  100]\n",
            "loss: 0.040650  [   10 /  100]\n",
            "loss: 0.044139  [   20 /  100]\n",
            "loss: 0.037943  [   30 /  100]\n",
            "loss: 0.034717  [   40 /  100]\n",
            "loss: 0.037539  [   50 /  100]\n",
            "loss: 0.038039  [   60 /  100]\n",
            "loss: 0.035879  [   70 /  100]\n",
            "loss: 0.037757  [   80 /  100]\n",
            "loss: 0.036471  [   90 /  100]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.032864  [    0 /  100]\n",
            "loss: 0.029932  [   10 /  100]\n",
            "loss: 0.032510  [   20 /  100]\n",
            "loss: 0.027759  [   30 /  100]\n",
            "loss: 0.025136  [   40 /  100]\n",
            "loss: 0.027794  [   50 /  100]\n",
            "loss: 0.028199  [   60 /  100]\n",
            "loss: 0.026316  [   70 /  100]\n",
            "loss: 0.028724  [   80 /  100]\n",
            "loss: 0.027332  [   90 /  100]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.023494  [    0 /  100]\n",
            "loss: 0.021539  [   10 /  100]\n",
            "loss: 0.023581  [   20 /  100]\n",
            "loss: 0.019981  [   30 /  100]\n",
            "loss: 0.017991  [   40 /  100]\n",
            "loss: 0.020483  [   50 /  100]\n",
            "loss: 0.020811  [   60 /  100]\n",
            "loss: 0.019228  [   70 /  100]\n",
            "loss: 0.021979  [   80 /  100]\n",
            "loss: 0.020687  [   90 /  100]\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.016927  [    0 /  100]\n",
            "loss: 0.015651  [   10 /  100]\n",
            "loss: 0.017465  [   20 /  100]\n",
            "loss: 0.014700  [   30 /  100]\n",
            "loss: 0.013251  [   40 /  100]\n",
            "loss: 0.015643  [   50 /  100]\n",
            "loss: 0.015805  [   60 /  100]\n",
            "loss: 0.014403  [   70 /  100]\n",
            "loss: 0.017342  [   80 /  100]\n",
            "loss: 0.016202  [   90 /  100]\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.012619  [    0 /  100]\n",
            "loss: 0.011778  [   10 /  100]\n",
            "loss: 0.013527  [   20 /  100]\n",
            "loss: 0.011306  [   30 /  100]\n",
            "loss: 0.010276  [   40 /  100]\n",
            "loss: 0.012563  [   50 /  100]\n",
            "loss: 0.012513  [   60 /  100]\n",
            "loss: 0.011212  [   70 /  100]\n",
            "loss: 0.014238  [   80 /  100]\n",
            "loss: 0.013273  [   90 /  100]\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.009935  [    0 /  100]\n",
            "loss: 0.009329  [   10 /  100]\n",
            "loss: 0.011116  [   20 /  100]\n",
            "loss: 0.009244  [   30 /  100]\n",
            "loss: 0.008518  [   40 /  100]\n",
            "loss: 0.010699  [   50 /  100]\n",
            "loss: 0.010434  [   60 /  100]\n",
            "loss: 0.009179  [   70 /  100]\n",
            "loss: 0.012204  [   80 /  100]\n",
            "loss: 0.011420  [   90 /  100]\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.008347  [    0 /  100]\n",
            "loss: 0.007840  [   10 /  100]\n",
            "loss: 0.009709  [   20 /  100]\n",
            "loss: 0.008020  [   30 /  100]\n",
            "loss: 0.007519  [   40 /  100]\n",
            "loss: 0.009587  [   50 /  100]\n",
            "loss: 0.009118  [   60 /  100]\n",
            "loss: 0.007889  [   70 /  100]\n",
            "loss: 0.010873  [   80 /  100]\n",
            "loss: 0.010255  [   90 /  100]\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.007441  [    0 /  100]\n",
            "loss: 0.006976  [   10 /  100]\n",
            "loss: 0.008981  [   20 /  100]\n",
            "loss: 0.007402  [   30 /  100]\n",
            "loss: 0.007069  [   40 /  100]\n",
            "loss: 0.009081  [   50 /  100]\n",
            "loss: 0.008416  [   60 /  100]\n",
            "loss: 0.007163  [   70 /  100]\n",
            "loss: 0.010112  [   80 /  100]\n",
            "loss: 0.009637  [   90 /  100]\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.007004  [    0 /  100]\n",
            "loss: 0.006526  [   10 /  100]\n",
            "loss: 0.008643  [   20 /  100]\n",
            "loss: 0.007094  [   30 /  100]\n",
            "loss: 0.006864  [   40 /  100]\n",
            "loss: 0.008800  [   50 /  100]\n",
            "loss: 0.007995  [   60 /  100]\n",
            "loss: 0.006739  [   70 /  100]\n",
            "loss: 0.009624  [   80 /  100]\n",
            "loss: 0.009241  [   90 /  100]\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.006749  [    0 /  100]\n",
            "loss: 0.006244  [   10 /  100]\n",
            "loss: 0.008437  [   20 /  100]\n",
            "loss: 0.006880  [   30 /  100]\n",
            "loss: 0.006723  [   40 /  100]\n",
            "loss: 0.008596  [   50 /  100]\n",
            "loss: 0.007692  [   60 /  100]\n",
            "loss: 0.006440  [   70 /  100]\n",
            "loss: 0.009254  [   80 /  100]\n",
            "loss: 0.008940  [   90 /  100]\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.006562  [    0 /  100]\n",
            "loss: 0.006033  [   10 /  100]\n",
            "loss: 0.008266  [   20 /  100]\n",
            "loss: 0.006680  [   30 /  100]\n",
            "loss: 0.006589  [   40 /  100]\n",
            "loss: 0.008410  [   50 /  100]\n",
            "loss: 0.007443  [   60 /  100]\n",
            "loss: 0.006206  [   70 /  100]\n",
            "loss: 0.008940  [   80 /  100]\n",
            "loss: 0.008683  [   90 /  100]\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.006402  [    0 /  100]\n",
            "loss: 0.005856  [   10 /  100]\n",
            "loss: 0.008112  [   20 /  100]\n",
            "loss: 0.006515  [   30 /  100]\n",
            "loss: 0.006470  [   40 /  100]\n",
            "loss: 0.008232  [   50 /  100]\n",
            "loss: 0.007219  [   60 /  100]\n",
            "loss: 0.006010  [   70 /  100]\n",
            "loss: 0.008662  [   80 /  100]\n",
            "loss: 0.008448  [   90 /  100]\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.006251  [    0 /  100]\n",
            "loss: 0.005695  [   10 /  100]\n",
            "loss: 0.007960  [   20 /  100]\n",
            "loss: 0.006354  [   30 /  100]\n",
            "loss: 0.006340  [   40 /  100]\n",
            "loss: 0.008048  [   50 /  100]\n",
            "loss: 0.007013  [   60 /  100]\n",
            "loss: 0.005836  [   70 /  100]\n",
            "loss: 0.008403  [   80 /  100]\n",
            "loss: 0.008227  [   90 /  100]\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.006109  [    0 /  100]\n",
            "loss: 0.005547  [   10 /  100]\n",
            "loss: 0.007810  [   20 /  100]\n",
            "loss: 0.006200  [   30 /  100]\n",
            "loss: 0.006214  [   40 /  100]\n",
            "loss: 0.007867  [   50 /  100]\n",
            "loss: 0.006819  [   60 /  100]\n",
            "loss: 0.005678  [   70 /  100]\n",
            "loss: 0.008158  [   80 /  100]\n",
            "loss: 0.008014  [   90 /  100]\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.005973  [    0 /  100]\n",
            "loss: 0.005408  [   10 /  100]\n",
            "loss: 0.007662  [   20 /  100]\n",
            "loss: 0.006054  [   30 /  100]\n",
            "loss: 0.006090  [   40 /  100]\n",
            "loss: 0.007688  [   50 /  100]\n",
            "loss: 0.006634  [   60 /  100]\n",
            "loss: 0.005531  [   70 /  100]\n",
            "loss: 0.007924  [   80 /  100]\n",
            "loss: 0.007810  [   90 /  100]\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.005845  [    0 /  100]\n",
            "loss: 0.005281  [   10 /  100]\n",
            "loss: 0.007521  [   20 /  100]\n",
            "loss: 0.005922  [   30 /  100]\n",
            "loss: 0.005975  [   40 /  100]\n",
            "loss: 0.007519  [   50 /  100]\n",
            "loss: 0.006465  [   60 /  100]\n",
            "loss: 0.005407  [   70 /  100]\n",
            "loss: 0.007713  [   80 /  100]\n",
            "loss: 0.007620  [   90 /  100]\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.005726  [    0 /  100]\n",
            "loss: 0.005167  [   10 /  100]\n",
            "loss: 0.007387  [   20 /  100]\n",
            "loss: 0.005802  [   30 /  100]\n",
            "loss: 0.005867  [   40 /  100]\n",
            "loss: 0.007350  [   50 /  100]\n",
            "loss: 0.006306  [   60 /  100]\n",
            "loss: 0.005295  [   70 /  100]\n",
            "loss: 0.007493  [   80 /  100]\n",
            "loss: 0.007430  [   90 /  100]\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.005614  [    0 /  100]\n",
            "loss: 0.005056  [   10 /  100]\n",
            "loss: 0.007255  [   20 /  100]\n",
            "loss: 0.005682  [   30 /  100]\n",
            "loss: 0.005749  [   40 /  100]\n",
            "loss: 0.007146  [   50 /  100]\n",
            "loss: 0.006138  [   60 /  100]\n",
            "loss: 0.005170  [   70 /  100]\n",
            "loss: 0.007168  [   80 /  100]\n",
            "loss: 0.007040  [   90 /  100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = FactorNetwork_pr(4).to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model5.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 40\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop_pr(model5, loss_fn, optimizer, DISCOUNT_Pol, randPol, evalPolSoft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc2d71f-94d5-4fb4-f09d-2e18c5c7559f",
        "id": "dJuutG7c0DSI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.751205  [    0 /  100]\n",
            "loss: 1.670108  [   10 /  100]\n",
            "loss: 1.620225  [   20 /  100]\n",
            "loss: 1.548632  [   30 /  100]\n",
            "loss: 1.493559  [   40 /  100]\n",
            "loss: 1.436204  [   50 /  100]\n",
            "loss: 1.382522  [   60 /  100]\n",
            "loss: 1.329095  [   70 /  100]\n",
            "loss: 1.289697  [   80 /  100]\n",
            "loss: 1.252048  [   90 /  100]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.217517  [    0 /  100]\n",
            "loss: 1.187078  [   10 /  100]\n",
            "loss: 1.153870  [   20 /  100]\n",
            "loss: 1.124950  [   30 /  100]\n",
            "loss: 1.095177  [   40 /  100]\n",
            "loss: 1.077855  [   50 /  100]\n",
            "loss: 1.055181  [   60 /  100]\n",
            "loss: 1.020875  [   70 /  100]\n",
            "loss: 1.005256  [   80 /  100]\n",
            "loss: 0.994949  [   90 /  100]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.990857  [    0 /  100]\n",
            "loss: 0.960694  [   10 /  100]\n",
            "loss: 0.970160  [   20 /  100]\n",
            "loss: 0.930605  [   30 /  100]\n",
            "loss: 0.914517  [   40 /  100]\n",
            "loss: 0.912141  [   50 /  100]\n",
            "loss: 0.896678  [   60 /  100]\n",
            "loss: 0.878795  [   70 /  100]\n",
            "loss: 0.860957  [   80 /  100]\n",
            "loss: 0.864452  [   90 /  100]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.875788  [    0 /  100]\n",
            "loss: 0.834781  [   10 /  100]\n",
            "loss: 0.865323  [   20 /  100]\n",
            "loss: 0.812388  [   30 /  100]\n",
            "loss: 0.799033  [   40 /  100]\n",
            "loss: 0.797906  [   50 /  100]\n",
            "loss: 0.781345  [   60 /  100]\n",
            "loss: 0.765274  [   70 /  100]\n",
            "loss: 0.743798  [   80 /  100]\n",
            "loss: 0.747364  [   90 /  100]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.758640  [    0 /  100]\n",
            "loss: 0.714411  [   10 /  100]\n",
            "loss: 0.745804  [   20 /  100]\n",
            "loss: 0.689604  [   30 /  100]\n",
            "loss: 0.675369  [   40 /  100]\n",
            "loss: 0.672392  [   50 /  100]\n",
            "loss: 0.653988  [   60 /  100]\n",
            "loss: 0.636737  [   70 /  100]\n",
            "loss: 0.612929  [   80 /  100]\n",
            "loss: 0.614691  [   90 /  100]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.623883  [    0 /  100]\n",
            "loss: 0.577662  [   10 /  100]\n",
            "loss: 0.607039  [   20 /  100]\n",
            "loss: 0.548509  [   30 /  100]\n",
            "loss: 0.532709  [   40 /  100]\n",
            "loss: 0.526980  [   50 /  100]\n",
            "loss: 0.506037  [   60 /  100]\n",
            "loss: 0.486786  [   70 /  100]\n",
            "loss: 0.460301  [   80 /  100]\n",
            "loss: 0.460085  [   90 /  100]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.467080  [    0 /  100]\n",
            "loss: 0.420238  [   10 /  100]\n",
            "loss: 0.447352  [   20 /  100]\n",
            "loss: 0.388829  [   30 /  100]\n",
            "loss: 0.372584  [   40 /  100]\n",
            "loss: 0.369150  [   50 /  100]\n",
            "loss: 0.353119  [   60 /  100]\n",
            "loss: 0.337254  [   70 /  100]\n",
            "loss: 0.317797  [   80 /  100]\n",
            "loss: 0.322954  [   90 /  100]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.334335  [    0 /  100]\n",
            "loss: 0.297528  [   10 /  100]\n",
            "loss: 0.330294  [   20 /  100]\n",
            "loss: 0.287786  [   30 /  100]\n",
            "loss: 0.278708  [   40 /  100]\n",
            "loss: 0.286222  [   50 /  100]\n",
            "loss: 0.281416  [   60 /  100]\n",
            "loss: 0.272492  [   70 /  100]\n",
            "loss: 0.263880  [   80 /  100]\n",
            "loss: 0.276536  [   90 /  100]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.295101  [    0 /  100]\n",
            "loss: 0.266788  [   10 /  100]\n",
            "loss: 0.303887  [   20 /  100]\n",
            "loss: 0.267867  [   30 /  100]\n",
            "loss: 0.262691  [   40 /  100]\n",
            "loss: 0.273549  [   50 /  100]\n",
            "loss: 0.271145  [   60 /  100]\n",
            "loss: 0.263578  [   70 /  100]\n",
            "loss: 0.258202  [   80 /  100]\n",
            "loss: 0.271631  [   90 /  100]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.290484  [    0 /  100]\n",
            "loss: 0.264326  [   10 /  100]\n",
            "loss: 0.300461  [   20 /  100]\n",
            "loss: 0.265796  [   30 /  100]\n",
            "loss: 0.260484  [   40 /  100]\n",
            "loss: 0.271120  [   50 /  100]\n",
            "loss: 0.268663  [   60 /  100]\n",
            "loss: 0.261170  [   70 /  100]\n",
            "loss: 0.255701  [   80 /  100]\n",
            "loss: 0.268827  [   90 /  100]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.287279  [    0 /  100]\n",
            "loss: 0.260991  [   10 /  100]\n",
            "loss: 0.296756  [   20 /  100]\n",
            "loss: 0.261884  [   30 /  100]\n",
            "loss: 0.256420  [   40 /  100]\n",
            "loss: 0.266587  [   50 /  100]\n",
            "loss: 0.263768  [   60 /  100]\n",
            "loss: 0.256211  [   70 /  100]\n",
            "loss: 0.250344  [   80 /  100]\n",
            "loss: 0.262920  [   90 /  100]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.280715  [    0 /  100]\n",
            "loss: 0.254525  [   10 /  100]\n",
            "loss: 0.289288  [   20 /  100]\n",
            "loss: 0.254458  [   30 /  100]\n",
            "loss: 0.248999  [   40 /  100]\n",
            "loss: 0.258705  [   50 /  100]\n",
            "loss: 0.255958  [   60 /  100]\n",
            "loss: 0.248832  [   70 /  100]\n",
            "loss: 0.242965  [   80 /  100]\n",
            "loss: 0.255213  [   90 /  100]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.272441  [    0 /  100]\n",
            "loss: 0.247033  [   10 /  100]\n",
            "loss: 0.280809  [   20 /  100]\n",
            "loss: 0.247021  [   30 /  100]\n",
            "loss: 0.241782  [   40 /  100]\n",
            "loss: 0.251188  [   50 /  100]\n",
            "loss: 0.248483  [   60 /  100]\n",
            "loss: 0.241538  [   70 /  100]\n",
            "loss: 0.235735  [   80 /  100]\n",
            "loss: 0.247320  [   90 /  100]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.263751  [    0 /  100]\n",
            "loss: 0.238861  [   10 /  100]\n",
            "loss: 0.271515  [   20 /  100]\n",
            "loss: 0.238413  [   30 /  100]\n",
            "loss: 0.233090  [   40 /  100]\n",
            "loss: 0.242049  [   50 /  100]\n",
            "loss: 0.239384  [   60 /  100]\n",
            "loss: 0.232507  [   70 /  100]\n",
            "loss: 0.226712  [   80 /  100]\n",
            "loss: 0.237580  [   90 /  100]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.252966  [    0 /  100]\n",
            "loss: 0.228718  [   10 /  100]\n",
            "loss: 0.259780  [   20 /  100]\n",
            "loss: 0.227717  [   30 /  100]\n",
            "loss: 0.222264  [   40 /  100]\n",
            "loss: 0.230649  [   50 /  100]\n",
            "loss: 0.228010  [   60 /  100]\n",
            "loss: 0.221253  [   70 /  100]\n",
            "loss: 0.215533  [   80 /  100]\n",
            "loss: 0.225392  [   90 /  100]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.239465  [    0 /  100]\n",
            "loss: 0.216051  [   10 /  100]\n",
            "loss: 0.245221  [   20 /  100]\n",
            "loss: 0.214346  [   30 /  100]\n",
            "loss: 0.208703  [   40 /  100]\n",
            "loss: 0.216390  [   50 /  100]\n",
            "loss: 0.213795  [   60 /  100]\n",
            "loss: 0.207183  [   70 /  100]\n",
            "loss: 0.201559  [   80 /  100]\n",
            "loss: 0.210194  [   90 /  100]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.222601  [    0 /  100]\n",
            "loss: 0.200325  [   10 /  100]\n",
            "loss: 0.226988  [   20 /  100]\n",
            "loss: 0.197760  [   30 /  100]\n",
            "loss: 0.191901  [   40 /  100]\n",
            "loss: 0.198749  [   50 /  100]\n",
            "loss: 0.196235  [   60 /  100]\n",
            "loss: 0.189814  [   70 /  100]\n",
            "loss: 0.184352  [   80 /  100]\n",
            "loss: 0.191517  [   90 /  100]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.201872  [    0 /  100]\n",
            "loss: 0.181056  [   10 /  100]\n",
            "loss: 0.204710  [   20 /  100]\n",
            "loss: 0.177630  [   30 /  100]\n",
            "loss: 0.171553  [   40 /  100]\n",
            "loss: 0.177426  [   50 /  100]\n",
            "loss: 0.175082  [   60 /  100]\n",
            "loss: 0.168852  [   70 /  100]\n",
            "loss: 0.163765  [   80 /  100]\n",
            "loss: 0.169203  [   90 /  100]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.177213  [    0 /  100]\n",
            "loss: 0.158272  [   10 /  100]\n",
            "loss: 0.178280  [   20 /  100]\n",
            "loss: 0.153963  [   30 /  100]\n",
            "loss: 0.147747  [   40 /  100]\n",
            "loss: 0.152618  [   50 /  100]\n",
            "loss: 0.150501  [   60 /  100]\n",
            "loss: 0.144574  [   70 /  100]\n",
            "loss: 0.139872  [   80 /  100]\n",
            "loss: 0.142912  [   90 /  100]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.147406  [    0 /  100]\n",
            "loss: 0.130858  [   10 /  100]\n",
            "loss: 0.145138  [   20 /  100]\n",
            "loss: 0.124471  [   30 /  100]\n",
            "loss: 0.117766  [   40 /  100]\n",
            "loss: 0.120660  [   50 /  100]\n",
            "loss: 0.118373  [   60 /  100]\n",
            "loss: 0.112231  [   70 /  100]\n",
            "loss: 0.108102  [   80 /  100]\n",
            "loss: 0.108701  [   90 /  100]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.110082  [    0 /  100]\n",
            "loss: 0.096951  [   10 /  100]\n",
            "loss: 0.106231  [   20 /  100]\n",
            "loss: 0.090296  [   30 /  100]\n",
            "loss: 0.083953  [   40 /  100]\n",
            "loss: 0.085800  [   50 /  100]\n",
            "loss: 0.084376  [   60 /  100]\n",
            "loss: 0.079561  [   70 /  100]\n",
            "loss: 0.076748  [   80 /  100]\n",
            "loss: 0.076031  [   90 /  100]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.075595  [    0 /  100]\n",
            "loss: 0.066078  [   10 /  100]\n",
            "loss: 0.071775  [   20 /  100]\n",
            "loss: 0.060466  [   30 /  100]\n",
            "loss: 0.055442  [   40 /  100]\n",
            "loss: 0.056795  [   50 /  100]\n",
            "loss: 0.056249  [   60 /  100]\n",
            "loss: 0.052763  [   70 /  100]\n",
            "loss: 0.051051  [   80 /  100]\n",
            "loss: 0.049731  [   90 /  100]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.048363  [    0 /  100]\n",
            "loss: 0.041984  [   10 /  100]\n",
            "loss: 0.045191  [   20 /  100]\n",
            "loss: 0.037628  [   30 /  100]\n",
            "loss: 0.033889  [   40 /  100]\n",
            "loss: 0.034870  [   50 /  100]\n",
            "loss: 0.034839  [   60 /  100]\n",
            "loss: 0.032468  [   70 /  100]\n",
            "loss: 0.031552  [   80 /  100]\n",
            "loss: 0.030077  [   90 /  100]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.028424  [    0 /  100]\n",
            "loss: 0.024476  [   10 /  100]\n",
            "loss: 0.026065  [   20 /  100]\n",
            "loss: 0.021428  [   30 /  100]\n",
            "loss: 0.018909  [   40 /  100]\n",
            "loss: 0.019628  [   50 /  100]\n",
            "loss: 0.019883  [   60 /  100]\n",
            "loss: 0.018508  [   70 /  100]\n",
            "loss: 0.018049  [   80 /  100]\n",
            "loss: 0.016854  [   90 /  100]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.015589  [    0 /  100]\n",
            "loss: 0.013303  [   10 /  100]\n",
            "loss: 0.014140  [   20 /  100]\n",
            "loss: 0.011548  [   30 /  100]\n",
            "loss: 0.010049  [   40 /  100]\n",
            "loss: 0.010604  [   50 /  100]\n",
            "loss: 0.010889  [   60 /  100]\n",
            "loss: 0.010235  [   70 /  100]\n",
            "loss: 0.009942  [   80 /  100]\n",
            "loss: 0.009262  [   90 /  100]\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.008627  [    0 /  100]\n",
            "loss: 0.007289  [   10 /  100]\n",
            "loss: 0.008003  [   20 /  100]\n",
            "loss: 0.006492  [   30 /  100]\n",
            "loss: 0.005750  [   40 /  100]\n",
            "loss: 0.006124  [   50 /  100]\n",
            "loss: 0.006238  [   60 /  100]\n",
            "loss: 0.006023  [   70 /  100]\n",
            "loss: 0.005677  [   80 /  100]\n",
            "loss: 0.005459  [   90 /  100]\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.005407  [    0 /  100]\n",
            "loss: 0.004491  [   10 /  100]\n",
            "loss: 0.005340  [   20 /  100]\n",
            "loss: 0.004269  [   30 /  100]\n",
            "loss: 0.003964  [   40 /  100]\n",
            "loss: 0.004234  [   50 /  100]\n",
            "loss: 0.004082  [   60 /  100]\n",
            "loss: 0.004041  [   70 /  100]\n",
            "loss: 0.003633  [   80 /  100]\n",
            "loss: 0.003748  [   90 /  100]\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.004121  [    0 /  100]\n",
            "loss: 0.003340  [   10 /  100]\n",
            "loss: 0.004377  [   20 /  100]\n",
            "loss: 0.003467  [   30 /  100]\n",
            "loss: 0.003374  [   40 /  100]\n",
            "loss: 0.003510  [   50 /  100]\n",
            "loss: 0.003141  [   60 /  100]\n",
            "loss: 0.003222  [   70 /  100]\n",
            "loss: 0.002619  [   80 /  100]\n",
            "loss: 0.003012  [   90 /  100]\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.003653  [    0 /  100]\n",
            "loss: 0.002893  [   10 /  100]\n",
            "loss: 0.004076  [   20 /  100]\n",
            "loss: 0.003182  [   30 /  100]\n",
            "loss: 0.003229  [   40 /  100]\n",
            "loss: 0.003298  [   50 /  100]\n",
            "loss: 0.002747  [   60 /  100]\n",
            "loss: 0.002891  [   70 /  100]\n",
            "loss: 0.002195  [   80 /  100]\n",
            "loss: 0.002702  [   90 /  100]\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.003508  [    0 /  100]\n",
            "loss: 0.002725  [   10 /  100]\n",
            "loss: 0.004017  [   20 /  100]\n",
            "loss: 0.003108  [   30 /  100]\n",
            "loss: 0.003205  [   40 /  100]\n",
            "loss: 0.003233  [   50 /  100]\n",
            "loss: 0.002576  [   60 /  100]\n",
            "loss: 0.002710  [   70 /  100]\n",
            "loss: 0.001990  [   80 /  100]\n",
            "loss: 0.002577  [   90 /  100]\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.003452  [    0 /  100]\n",
            "loss: 0.002656  [   10 /  100]\n",
            "loss: 0.004017  [   20 /  100]\n",
            "loss: 0.003074  [   30 /  100]\n",
            "loss: 0.003218  [   40 /  100]\n",
            "loss: 0.003217  [   50 /  100]\n",
            "loss: 0.002503  [   60 /  100]\n",
            "loss: 0.002637  [   70 /  100]\n",
            "loss: 0.001898  [   80 /  100]\n",
            "loss: 0.002511  [   90 /  100]\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.003442  [    0 /  100]\n",
            "loss: 0.002627  [   10 /  100]\n",
            "loss: 0.004036  [   20 /  100]\n",
            "loss: 0.003066  [   30 /  100]\n",
            "loss: 0.003228  [   40 /  100]\n",
            "loss: 0.003216  [   50 /  100]\n",
            "loss: 0.002467  [   60 /  100]\n",
            "loss: 0.002601  [   70 /  100]\n",
            "loss: 0.001855  [   80 /  100]\n",
            "loss: 0.002482  [   90 /  100]\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.003434  [    0 /  100]\n",
            "loss: 0.002613  [   10 /  100]\n",
            "loss: 0.004049  [   20 /  100]\n",
            "loss: 0.003057  [   30 /  100]\n",
            "loss: 0.003236  [   40 /  100]\n",
            "loss: 0.003215  [   50 /  100]\n",
            "loss: 0.002449  [   60 /  100]\n",
            "loss: 0.002582  [   70 /  100]\n",
            "loss: 0.001836  [   80 /  100]\n",
            "loss: 0.002468  [   90 /  100]\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.003430  [    0 /  100]\n",
            "loss: 0.002605  [   10 /  100]\n",
            "loss: 0.004059  [   20 /  100]\n",
            "loss: 0.003051  [   30 /  100]\n",
            "loss: 0.003242  [   40 /  100]\n",
            "loss: 0.003214  [   50 /  100]\n",
            "loss: 0.002441  [   60 /  100]\n",
            "loss: 0.002573  [   70 /  100]\n",
            "loss: 0.001829  [   80 /  100]\n",
            "loss: 0.002461  [   90 /  100]\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.003426  [    0 /  100]\n",
            "loss: 0.002601  [   10 /  100]\n",
            "loss: 0.004066  [   20 /  100]\n",
            "loss: 0.003045  [   30 /  100]\n",
            "loss: 0.003248  [   40 /  100]\n",
            "loss: 0.003212  [   50 /  100]\n",
            "loss: 0.002436  [   60 /  100]\n",
            "loss: 0.002567  [   70 /  100]\n",
            "loss: 0.001828  [   80 /  100]\n",
            "loss: 0.002456  [   90 /  100]\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.003417  [    0 /  100]\n",
            "loss: 0.002598  [   10 /  100]\n",
            "loss: 0.004072  [   20 /  100]\n",
            "loss: 0.003035  [   30 /  100]\n",
            "loss: 0.003253  [   40 /  100]\n",
            "loss: 0.003208  [   50 /  100]\n",
            "loss: 0.002434  [   60 /  100]\n",
            "loss: 0.002565  [   70 /  100]\n",
            "loss: 0.001832  [   80 /  100]\n",
            "loss: 0.002454  [   90 /  100]\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.003419  [    0 /  100]\n",
            "loss: 0.002598  [   10 /  100]\n",
            "loss: 0.004073  [   20 /  100]\n",
            "loss: 0.003034  [   30 /  100]\n",
            "loss: 0.003256  [   40 /  100]\n",
            "loss: 0.003206  [   50 /  100]\n",
            "loss: 0.002431  [   60 /  100]\n",
            "loss: 0.002564  [   70 /  100]\n",
            "loss: 0.001833  [   80 /  100]\n",
            "loss: 0.002452  [   90 /  100]\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.003417  [    0 /  100]\n",
            "loss: 0.002597  [   10 /  100]\n",
            "loss: 0.004076  [   20 /  100]\n",
            "loss: 0.003030  [   30 /  100]\n",
            "loss: 0.003262  [   40 /  100]\n",
            "loss: 0.003203  [   50 /  100]\n",
            "loss: 0.002429  [   60 /  100]\n",
            "loss: 0.002564  [   70 /  100]\n",
            "loss: 0.001835  [   80 /  100]\n",
            "loss: 0.002450  [   90 /  100]\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.003415  [    0 /  100]\n",
            "loss: 0.002597  [   10 /  100]\n",
            "loss: 0.004077  [   20 /  100]\n",
            "loss: 0.003027  [   30 /  100]\n",
            "loss: 0.003268  [   40 /  100]\n",
            "loss: 0.003199  [   50 /  100]\n",
            "loss: 0.002427  [   60 /  100]\n",
            "loss: 0.002566  [   70 /  100]\n",
            "loss: 0.001838  [   80 /  100]\n",
            "loss: 0.002449  [   90 /  100]\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.003413  [    0 /  100]\n",
            "loss: 0.002597  [   10 /  100]\n",
            "loss: 0.004075  [   20 /  100]\n",
            "loss: 0.003024  [   30 /  100]\n",
            "loss: 0.003272  [   40 /  100]\n",
            "loss: 0.003196  [   50 /  100]\n",
            "loss: 0.002426  [   60 /  100]\n",
            "loss: 0.002569  [   70 /  100]\n",
            "loss: 0.001840  [   80 /  100]\n",
            "loss: 0.002448  [   90 /  100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate a new batch of behaviour data"
      ],
      "metadata": {
        "id": "reumIqKKv84J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K_fWXVK6S4w"
      },
      "source": [
        "Run the data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in3w55oZ6S4w"
      },
      "outputs": [],
      "source": [
        "randPol = np.ones(fullPol.shape)/(fullPol.shape[1])\n",
        "\n",
        "states, actions, lengths, rewards, diab, emp_tx_totals, emp_r_totals = dgen.simulate(\n",
        "    NSIMSAMPS, NSTEPS, policy=randPol, policy_idx_type='full',\n",
        "    p_diabetes=PROB_DIAB, use_tqdm=False) #True, tqdm_desc='Behaviour Policy Simulation')\n",
        "\n",
        "obs_samps = utils.format_dgen_samps(\n",
        "    states, actions, rewards, diab, NSTEPS, NSIMSAMPS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJwI24gq6S4x"
      },
      "source": [
        "Convert data into array format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dffbaf-b2f3-4d65-c327-f2195555c16d",
        "id": "Wg7pZWVD6S4x"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 20, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "time = np.arange(NSTEPS)\n",
        "times = np.stack(axis=0, arrays=[time]*NSIMSAMPS)\n",
        "times = times[..., np.newaxis]\n",
        "\n",
        "nf_tr_b2 = np.concatenate((times, states[:, 0:NSTEPS, :], actions, rewards, states[:, 1:, :]), axis=2)\n",
        "nf_tr_b2.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_sa(model):\n",
        "  test_data = nf_tr_b2\n",
        "  model.eval()\n",
        "  loss = torch.zeros((1), dtype=torch.float32).to(device)\n",
        "  for run in range(test_data.shape[0]):\n",
        "    episode = test_data[run, :, :]\n",
        "    #Filter out -1 states and actions\n",
        "    episode = episode[episode[:, 2] != -1, :]\n",
        "    states_and_actions = torch.as_tensor(episode[:, 1:3], dtype=torch.float32).to(device)\n",
        "    # Compute prediction and loss\n",
        "    factored_pol_reward = model(states_and_actions) #Use predictions from network to calculate OPE estimates\n",
        "    D = list(factored_pol_reward.size())[-1]//3\n",
        "    factored_pi_b = factored_pol_reward[:, :D]\n",
        "    factored_pi_e = factored_pol_reward[:, D:2*D]\n",
        "    factored_reward = factored_pol_reward[:, 2*D:]\n",
        "\n",
        "    pointwise_IS_ratios = torch.div(factored_pi_e, factored_pi_b)\n",
        "    IS_ratios = torch.prod(pointwise_IS_ratios, 0)\n",
        "\n",
        "    times = torch.as_tensor(np.repeat(np.expand_dims(episode[:, 0], axis=1), D, axis=1)).to(device)\n",
        "    # Per-trajectory returns (discounted cumulative rewards)\n",
        "    gamma = torch.full(times.shape, DISCOUNT_Pol).to(device)\n",
        "    G = torch.mul(factored_reward, torch.pow(gamma, times)).sum()\n",
        "\n",
        "    loss.to(device)\n",
        "    loss = torch.add(loss, loss_fn(true_val, G).div(test_data.shape[0]))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "cizuN0cmlzv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_sa(model1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TQgq35GzwxQ",
        "outputId": "2ccfb5d6-62a2-42a0-cca1-2816f5c05dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1903], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model1.state_dict(), './model1e004')"
      ],
      "metadata": {
        "id": "-_YNW6JwCOHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model_sa(model2))"
      ],
      "metadata": {
        "id": "mEBIu6ZuFa1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09dba4f-eca8-49d0-a180-cd653049f5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1849], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model2.state_dict(), './model2e004')"
      ],
      "metadata": {
        "id": "2y9PBEy9z4YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_rp(model, pi_b, pi_e, discount_factor):\n",
        "  test_data = nf_tr_b2\n",
        "  model.eval()\n",
        "  loss = torch.zeros((1), dtype=torch.float32).to(device)\n",
        "  for run in range(test_data.shape[0]):\n",
        "    episode = test_data[run, :, :]\n",
        "    #Filter out -1 states and actions\n",
        "    episode = episode[episode[:, 2] != -1, :]\n",
        "    S = episode[:, 1].astype('int32')\n",
        "    A = episode[:,2].astype('int32')\n",
        "    states_and_actions = torch.as_tensor(np.stack((pi_b[S, A], pi_e[S, A], episode[:,3]), axis=-1), dtype=torch.float32).to(device)\n",
        "    # Compute prediction and loss\n",
        "    factored_pol_reward = model(states_and_actions) #Use predictions from network to calculate OPE estimates\n",
        "    D = list(factored_pol_reward.size())[-1]//3\n",
        "    factored_pi_b = factored_pol_reward[:, :D]\n",
        "    factored_pi_e = factored_pol_reward[:, D:2*D]\n",
        "    factored_reward = factored_pol_reward[:, 2*D:]\n",
        "\n",
        "    pointwise_IS_ratios = torch.div(factored_pi_e, factored_pi_b)\n",
        "    IS_ratios = torch.prod(pointwise_IS_ratios, 0)\n",
        "\n",
        "    times = torch.as_tensor(np.repeat(np.expand_dims(episode[:, 0], axis=1), D, axis=1)).to(device)\n",
        "    # Per-trajectory returns (discounted cumulative rewards)\n",
        "    gamma = torch.full(times.shape, discount_factor).to(device)\n",
        "    G = torch.mul(factored_reward, torch.pow(gamma, times)).sum()\n",
        "\n",
        "    loss.to(device)\n",
        "    loss = torch.add(loss, loss_fn(true_val, G).div(test_data.shape[0]))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "nNnIKRjOpMS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model_rp(model3, randPol, evalPolSoft, DISCOUNT_Pol))"
      ],
      "metadata": {
        "id": "zvOurE2vw8U5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aaa7e33-ca82-426d-fccb-b995cdfd5f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0075], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model_rp(model4, randPol, evalPolSoft, DISCOUNT_Pol))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaRTKaMwqOfn",
        "outputId": "5ffba9d7-e585-4b0f-8b9e-a2e754254375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0029], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model_rp(model5, randPol, evalPolSoft, DISCOUNT_Pol))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb7bb35-9e12-4162-9a66-667b03f1b448",
        "id": "Rj8s4jwCMehF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0029], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model3.state_dict(), './model3e004')"
      ],
      "metadata": {
        "id": "TF4eX-t9Vhmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model4.state_dict(), './model4e004')"
      ],
      "metadata": {
        "id": "Lea3DMJsfNc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model5.state_dict(), './model5e004')"
      ],
      "metadata": {
        "id": "0m-SDIBhOBdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting Graphs"
      ],
      "metadata": {
        "id": "8CfFhj8ML0n9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 2"
      ],
      "metadata": {
        "id": "mQPEmphQMmpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_axis = losses_m2\n",
        "x_axis = np.arange(0, 70, 0.1)\n",
        "\n",
        "\n",
        "plt.plot(x_axis, y_axis, color='b', linewidth=1.0)\n",
        "plt.grid(visible=True, which='both', axis='both')\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel('Epochs Completed')\n",
        "plt.ylabel('Objective Value')\n",
        "plt.ylim([10**(-1), 100])\n",
        "plt.savefig(f'model-2-learning-curve.pdf', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wR0glJP8MKZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "aa90ca93-c949-4e03-d71d-541e5d713cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 3"
      ],
      "metadata": {
        "id": "OVWqF45LMpFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_axis = losses_m4\n",
        "x_axis = np.arange(0, 40, 0.1)\n",
        "\n",
        "\n",
        "plt.plot(x_axis, y_axis, color='r', linewidth=1.0)\n",
        "plt.grid(visible=True, which='both', axis='both')\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel('Epochs Completed')\n",
        "plt.ylabel('Objective Value')\n",
        "plt.ylim([10**(-3), 100])\n",
        "plt.savefig(f'model-4-learning-curve.pdf', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SbN0dk35MrH9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "fc808352-684a-4c51-81dc-6621fcf95c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7Zt7QLKc3iQ7",
        "5W3Fj_q5EADA",
        "TPF8wN8gNZEK"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}